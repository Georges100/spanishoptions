{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD & CLEAN FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "novoptions=pd.read_csv(\"/users/jorge/downloads/nov14opt.csv\")\n",
    "\n",
    "nov_opt=novoptions[(novoptions[\"VOLUME\"]!=0)]\n",
    "nov_opt=nov_opt[nov_opt['CODE'].str.contains(\"AM\")]\n",
    "nov_opt=nov_opt[nov_opt['CODE'].str.startswith(\"C\")]\n",
    "\n",
    "nov_opt.to_csv(\"nov_clean14.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "novoptions=pd.read_csv(\"/users/jorge/nov_clean14.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nov_opt=novoptions\n",
    "import datetime\n",
    "fecha=nov_opt[\"DATE\"]\n",
    "nov_opt[\"DATE\"] = pd.to_datetime(nov_opt[\"DATE\"],format='%Y%m%d')\n",
    "nov_opt[\"STRIKE_DATE\"] = pd.to_datetime(nov_opt[\"STRIKE_DATE\"],format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD HISTORICAL STOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "abbmc=pd.read_csv(\"/users/jorge/downloads/abbmc.csv\")\n",
    "\n",
    "abbmc[\"Date\"] = pd.to_datetime(abbmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "abbmc_options=nov_opt[nov_opt['CODE'].str.contains(\"ABB\")]\n",
    "abbmc_options[\"money\"]= abbmc_options[\"STRIKE\"] - abbmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=abbmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=abbmc[(abbmc[\"Date\"] > abbmc_options[\"DATE\"].iloc[i]) & (abbmc[\"Date\"] < abbmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "abbmc_options[\"MIN\"]=sanvrai\n",
    "abbmc_optionsdate= abbmc_options[abbmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=abbmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=abbmc[(abbmc[\"Date\"] > abbmc_optionsdate[\"DATE\"].iloc[i]) & (abbmc[\"Date\"] < abbmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "abbmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=abbmc[abbmc[\"Date\"] == abbmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=abbmc[abbmc[\"Date\"] == abbmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "abbmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=abbmc[(abbmc[\"Date\"]>\"2013-11-01\") & (abbmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "abbmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=abbmc[(abbmc[\"Date\"]>\"2014-05-01\") & (abbmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "abbmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=abbmc[(abbmc[\"Date\"]>\"2014-08-01\") & (abbmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "abbmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "\n",
    "abemc=pd.read_csv(\"/users/jorge/downloads/abemc.csv\")\n",
    "\n",
    "abemc[\"Date\"] = pd.to_datetime(abemc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "abemc_options=nov_opt[nov_opt['CODE'].str.contains(\"ABE\")]\n",
    "abemc_options[\"money\"]= abemc_options[\"STRIKE\"] - abemc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=abemc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=abemc[(abemc[\"Date\"] > abemc_options[\"DATE\"].iloc[i]) & (abemc[\"Date\"] < abemc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "abemc_options[\"MIN\"]=sanvrai\n",
    "abemc_optionsdate= abemc_options[abemc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=abemc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=abemc[(abemc[\"Date\"] > abemc_optionsdate[\"DATE\"].iloc[i]) & (abemc[\"Date\"] < abemc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "abemc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=abemc[abemc[\"Date\"] == abemc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=abemc[abemc[\"Date\"] == abemc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "abemc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=abemc[(abemc[\"Date\"]>\"2013-11-01\") & (abemc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "abemc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=abemc[(abemc[\"Date\"]>\"2014-05-01\") & (abemc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "abemc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=abemc[(abemc[\"Date\"]>\"2014-08-01\") & (abemc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "abemc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "acsmc=pd.read_csv(\"/users/jorge/downloads/acsmc.csv\")\n",
    "\n",
    "acsmc[\"Date\"] = pd.to_datetime(acsmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "acsmc_options=nov_opt[nov_opt['CODE'].str.contains(\"ACS\")]\n",
    "acsmc_options[\"money\"]= acsmc_options[\"STRIKE\"] - acsmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=acsmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=acsmc[(acsmc[\"Date\"] > acsmc_options[\"DATE\"].iloc[i]) & (acsmc[\"Date\"] < acsmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "acsmc_options[\"MIN\"]=sanvrai\n",
    "acsmc_optionsdate= acsmc_options[acsmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=acsmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=acsmc[(acsmc[\"Date\"] > acsmc_optionsdate[\"DATE\"].iloc[i]) & (acsmc[\"Date\"] < acsmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "acsmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=acsmc[acsmc[\"Date\"] == acsmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=acsmc[acsmc[\"Date\"] == acsmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "acsmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=acsmc[(acsmc[\"Date\"]>\"2013-11-01\") & (acsmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "acsmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=acsmc[(acsmc[\"Date\"]>\"2014-05-01\") & (acsmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "acsmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=acsmc[(acsmc[\"Date\"]>\"2014-08-01\") & (acsmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "acsmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "acxmc=pd.read_csv(\"/users/jorge/downloads/acxmc.csv\")\n",
    "\n",
    "acxmc[\"Date\"] = pd.to_datetime(acxmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "acxmc_options=nov_opt[nov_opt['CODE'].str.contains(\"ACX\")]\n",
    "acxmc_options[\"money\"]= acxmc_options[\"STRIKE\"] - acxmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=acxmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=acxmc[(acxmc[\"Date\"] > acxmc_options[\"DATE\"].iloc[i]) & (acxmc[\"Date\"] < acxmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "acxmc_options[\"MIN\"]=sanvrai\n",
    "acxmc_optionsdate= acxmc_options[acxmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=acxmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=acxmc[(acxmc[\"Date\"] > acxmc_optionsdate[\"DATE\"].iloc[i]) & (acxmc[\"Date\"] < acxmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "acxmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=acxmc[acxmc[\"Date\"] == acxmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=acxmc[acxmc[\"Date\"] == acxmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "acxmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=acxmc[(acxmc[\"Date\"]>\"2013-11-01\") & (acxmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "acxmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=acxmc[(acxmc[\"Date\"]>\"2014-05-01\") & (acxmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "acxmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=acxmc[(acxmc[\"Date\"]>\"2014-08-01\") & (acxmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "acxmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "amsmc=pd.read_csv(\"/users/jorge/downloads/amsmc.csv\")\n",
    "\n",
    "amsmc[\"Date\"] = pd.to_datetime(amsmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "amsmc_options=nov_opt[nov_opt['CODE'].str.contains(\"AMS\")]\n",
    "amsmc_options[\"money\"]= amsmc_options[\"STRIKE\"] - amsmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=amsmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=amsmc[(amsmc[\"Date\"] > amsmc_options[\"DATE\"].iloc[i]) & (amsmc[\"Date\"] < amsmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "amsmc_options[\"MIN\"]=sanvrai\n",
    "amsmc_optionsdate= amsmc_options[amsmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=amsmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=amsmc[(amsmc[\"Date\"] > amsmc_optionsdate[\"DATE\"].iloc[i]) & (amsmc[\"Date\"] < amsmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "amsmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=amsmc[amsmc[\"Date\"] == amsmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=amsmc[amsmc[\"Date\"] == amsmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "amsmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=amsmc[(amsmc[\"Date\"]>\"2013-11-01\") & (amsmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "amsmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=amsmc[(amsmc[\"Date\"]>\"2014-05-01\") & (amsmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "amsmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=amsmc[(amsmc[\"Date\"]>\"2014-08-01\") & (amsmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "amsmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "anamc=pd.read_csv(\"/users/jorge/downloads/anamc.csv\")\n",
    "\n",
    "anamc[\"Date\"] = pd.to_datetime(anamc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "anamc_options=nov_opt[nov_opt['CODE'].str.contains(\"CANA\")]\n",
    "anamc_options[\"money\"]= anamc_options[\"STRIKE\"] - anamc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=anamc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=anamc[(anamc[\"Date\"] > anamc_options[\"DATE\"].iloc[i]) & (anamc[\"Date\"] < anamc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "anamc_options[\"MIN\"]=sanvrai\n",
    "anamc_optionsdate= anamc_options[anamc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=anamc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=anamc[(anamc[\"Date\"] > anamc_optionsdate[\"DATE\"].iloc[i]) & (anamc[\"Date\"] < anamc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "anamc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=anamc[anamc[\"Date\"] == anamc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=anamc[anamc[\"Date\"] == anamc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "anamc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=anamc[(anamc[\"Date\"]>\"2013-11-01\") & (anamc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "anamc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=anamc[(anamc[\"Date\"]>\"2014-05-01\") & (anamc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "anamc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=anamc[(anamc[\"Date\"]>\"2014-08-01\") & (anamc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "anamc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "bbvamc=pd.read_csv(\"/users/jorge/downloads/bbvamc.csv\")\n",
    "\n",
    "bbvamc[\"Date\"] = pd.to_datetime(bbvamc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "bbvamc_options=nov_opt[nov_opt['CODE'].str.contains(\"BBV\")]\n",
    "bbvamc_options[\"money\"]= bbvamc_options[\"STRIKE\"] - bbvamc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=bbvamc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=bbvamc[(bbvamc[\"Date\"] > bbvamc_options[\"DATE\"].iloc[i]) & (bbvamc[\"Date\"] < bbvamc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "bbvamc_options[\"MIN\"]=sanvrai\n",
    "bbvamc_optionsdate= bbvamc_options[bbvamc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=bbvamc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=bbvamc[(bbvamc[\"Date\"] > bbvamc_optionsdate[\"DATE\"].iloc[i]) & (bbvamc[\"Date\"] < bbvamc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "bbvamc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=bbvamc[bbvamc[\"Date\"] == bbvamc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=bbvamc[bbvamc[\"Date\"] == bbvamc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "bbvamc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=bbvamc[(bbvamc[\"Date\"]>\"2013-11-01\") & (bbvamc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bbvamc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=bbvamc[(bbvamc[\"Date\"]>\"2014-05-01\") & (bbvamc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "bbvamc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=bbvamc[(bbvamc[\"Date\"]>\"2014-08-01\") & (bbvamc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "bbvamc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "bkiamc=pd.read_csv(\"/users/jorge/downloads/bkiamc.csv\")\n",
    "\n",
    "bkiamc[\"Date\"] = pd.to_datetime(bkiamc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "bkiamc_options=nov_opt[nov_opt['CODE'].str.contains(\"BKIA\")]\n",
    "bkiamc_options[\"money\"]= bkiamc_options[\"STRIKE\"] - bkiamc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=bkiamc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=bkiamc[(bkiamc[\"Date\"] > bkiamc_options[\"DATE\"].iloc[i]) & (bkiamc[\"Date\"] < bkiamc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "bkiamc_options[\"MIN\"]=sanvrai\n",
    "bkiamc_optionsdate= bkiamc_options[bkiamc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=bkiamc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=bkiamc[(bkiamc[\"Date\"] > bkiamc_optionsdate[\"DATE\"].iloc[i]) & (bkiamc[\"Date\"] < bkiamc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "bkiamc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=bkiamc[bkiamc[\"Date\"] == bkiamc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=bkiamc[bkiamc[\"Date\"] == bkiamc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "bkiamc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=bkiamc[(bkiamc[\"Date\"]>\"2013-11-01\") & (bkiamc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bkiamc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=bkiamc[(bkiamc[\"Date\"]>\"2014-05-01\") & (bkiamc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "bkiamc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=bkiamc[(bkiamc[\"Date\"]>\"2014-08-01\") & (bkiamc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "bkiamc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "bktmc=pd.read_csv(\"/users/jorge/downloads/bktmc.csv\")\n",
    "\n",
    "bktmc[\"Date\"] = pd.to_datetime(bktmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "bktmc_options=nov_opt[nov_opt['CODE'].str.contains(\"BTK\")]\n",
    "bktmc_options[\"money\"]= bktmc_options[\"STRIKE\"] - bktmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=bktmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=bktmc[(bktmc[\"Date\"] > bktmc_options[\"DATE\"].iloc[i]) & (bktmc[\"Date\"] < bktmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "bktmc_options[\"MIN\"]=sanvrai\n",
    "bktmc_optionsdate= bktmc_options[bktmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=bktmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=bktmc[(bktmc[\"Date\"] > bktmc_optionsdate[\"DATE\"].iloc[i]) & (bktmc[\"Date\"] < bktmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "bktmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=bktmc[bktmc[\"Date\"] == bktmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=bktmc[bktmc[\"Date\"] == bktmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "bktmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=bktmc[(bktmc[\"Date\"]>\"2013-11-01\") & (bktmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bktmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=bktmc[(bktmc[\"Date\"]>\"2014-05-01\") & (bktmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "bktmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=bktmc[(bktmc[\"Date\"]>\"2014-08-01\") & (bktmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "bktmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "bmemc=pd.read_csv(\"/users/jorge/downloads/bmemc.csv\")\n",
    "\n",
    "bmemc[\"Date\"] = pd.to_datetime(bmemc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "bmemc_options=nov_opt[nov_opt['CODE'].str.contains(\"BME\")]\n",
    "bmemc_options[\"money\"]= bmemc_options[\"STRIKE\"] - bmemc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=bmemc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=bmemc[(bmemc[\"Date\"] > bmemc_options[\"DATE\"].iloc[i]) & (bmemc[\"Date\"] < bmemc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "bmemc_options[\"MIN\"]=sanvrai\n",
    "bmemc_optionsdate= bmemc_options[bmemc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=bmemc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=bmemc[(bmemc[\"Date\"] > bmemc_optionsdate[\"DATE\"].iloc[i]) & (bmemc[\"Date\"] < bmemc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "bmemc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=bmemc[bmemc[\"Date\"] == bmemc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=bmemc[bmemc[\"Date\"] == bmemc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "bmemc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=bmemc[(bmemc[\"Date\"]>\"2013-11-01\") & (bmemc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bmemc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=bmemc[(bmemc[\"Date\"]>\"2014-05-01\") & (bmemc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "bmemc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=bmemc[(bmemc[\"Date\"]>\"2014-08-01\") & (bmemc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "bmemc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "cabmc=pd.read_csv(\"/users/jorge/downloads/cabmc.csv\")\n",
    "\n",
    "cabmc[\"Date\"] = pd.to_datetime(cabmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "cabmc_options=nov_opt[nov_opt['CODE'].str.contains(\"CCAB\")]\n",
    "cabmc_options[\"money\"]= cabmc_options[\"STRIKE\"] - cabmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=cabmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=cabmc[(cabmc[\"Date\"] > cabmc_options[\"DATE\"].iloc[i]) & (cabmc[\"Date\"] < cabmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"Adj Close\"].max())\n",
    "\n",
    "cabmc_options[\"MIN\"]=sanvrai\n",
    "cabmc_optionsdate= cabmc_options[cabmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=cabmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=cabmc[(cabmc[\"Date\"] > cabmc_optionsdate[\"DATE\"].iloc[i]) & (cabmc[\"Date\"] < cabmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"Adj Close\"].std())\n",
    "cabmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=cabmc[cabmc[\"Date\"] == cabmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=cabmc[cabmc[\"Date\"] == cabmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Adj Close\"].iloc[1] - gain[\"Adj Close\"].iloc[0]) / gain[\"Adj Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "cabmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=cabmc[(cabmc[\"Date\"]>\"2013-11-01\") & (cabmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"Adj Close\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cabmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=cabmc[(cabmc[\"Date\"]>\"2014-05-01\") & (cabmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"Adj Close\"].std())\n",
    "cabmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=cabmc[(cabmc[\"Date\"]>\"2014-08-01\") & (cabmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"Adj Close\"].std())\n",
    "cabmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "ebrmc=pd.read_csv(\"/users/jorge/downloads/ebrmc.csv\")\n",
    "\n",
    "ebrmc[\"Date\"] = pd.to_datetime(ebrmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "ebrmc_options=nov_opt[nov_opt['CODE'].str.contains(\"EBR\")]\n",
    "ebrmc_options[\"money\"]= ebrmc_options[\"STRIKE\"] - ebrmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=ebrmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=ebrmc[(ebrmc[\"Date\"] > ebrmc_options[\"DATE\"].iloc[i]) & (ebrmc[\"Date\"] < ebrmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "ebrmc_options[\"MIN\"]=sanvrai\n",
    "ebrmc_optionsdate= ebrmc_options[ebrmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=ebrmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=ebrmc[(ebrmc[\"Date\"] > ebrmc_optionsdate[\"DATE\"].iloc[i]) & (ebrmc[\"Date\"] < ebrmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "ebrmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=ebrmc[ebrmc[\"Date\"] == ebrmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=ebrmc[ebrmc[\"Date\"] == ebrmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "ebrmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=ebrmc[(ebrmc[\"Date\"]>\"2013-11-01\") & (ebrmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ebrmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=ebrmc[(ebrmc[\"Date\"]>\"2014-05-01\") & (ebrmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "ebrmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=ebrmc[(ebrmc[\"Date\"]>\"2014-08-01\") & (ebrmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "ebrmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "elemc=pd.read_csv(\"/users/jorge/downloads/elemc.csv\")\n",
    "\n",
    "elemc[\"Date\"] = pd.to_datetime(elemc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "elemc_options=nov_opt[nov_opt['CODE'].str.contains(\"ELE\")]\n",
    "elemc_options[\"money\"]= elemc_options[\"STRIKE\"] - elemc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=elemc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=elemc[(elemc[\"Date\"] > elemc_options[\"DATE\"].iloc[i]) & (elemc[\"Date\"] < elemc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "elemc_options[\"MIN\"]=sanvrai\n",
    "elemc_optionsdate= elemc_options[elemc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=elemc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=elemc[(elemc[\"Date\"] > elemc_optionsdate[\"DATE\"].iloc[i]) & (elemc[\"Date\"] < elemc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "elemc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=elemc[elemc[\"Date\"] == elemc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=elemc[elemc[\"Date\"] == elemc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "elemc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=elemc[(elemc[\"Date\"]>\"2013-11-01\") & (elemc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "elemc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=elemc[(elemc[\"Date\"]>\"2014-05-01\") & (elemc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "elemc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=elemc[(elemc[\"Date\"]>\"2014-08-01\") & (elemc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "elemc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "enamc=pd.read_csv(\"/users/jorge/downloads/enamc.csv\")\n",
    "\n",
    "enamc[\"Date\"] = pd.to_datetime(enamc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "enamc_options=nov_opt[nov_opt['CODE'].str.contains(\"CENA\")]\n",
    "enamc_options[\"money\"]= enamc_options[\"STRIKE\"] - enamc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=enamc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=enamc[(enamc[\"Date\"] > enamc_options[\"DATE\"].iloc[i]) & (enamc[\"Date\"] < enamc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "enamc_options[\"MIN\"]=sanvrai\n",
    "enamc_optionsdate= enamc_options[enamc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=enamc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=enamc[(enamc[\"Date\"] > enamc_optionsdate[\"DATE\"].iloc[i]) & (enamc[\"Date\"] < enamc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "enamc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=enamc[enamc[\"Date\"] == enamc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=enamc[enamc[\"Date\"] == enamc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "enamc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=enamc[(enamc[\"Date\"]>\"2013-11-01\") & (enamc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "enamc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=enamc[(enamc[\"Date\"]>\"2014-05-01\") & (enamc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "enamc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=enamc[(enamc[\"Date\"]>\"2014-08-01\") & (enamc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "enamc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "fccmc=pd.read_csv(\"/users/jorge/downloads/fccmc.csv\")\n",
    "\n",
    "fccmc[\"Date\"] = pd.to_datetime(fccmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "fccmc_options=nov_opt[nov_opt['CODE'].str.contains(\"FCC\")]\n",
    "fccmc_options[\"money\"]= fccmc_options[\"STRIKE\"] - fccmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=fccmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=fccmc[(fccmc[\"Date\"] > fccmc_options[\"DATE\"].iloc[i]) & (fccmc[\"Date\"] < fccmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "fccmc_options[\"MIN\"]=sanvrai\n",
    "fccmc_optionsdate= fccmc_options[fccmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=fccmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=fccmc[(fccmc[\"Date\"] > fccmc_optionsdate[\"DATE\"].iloc[i]) & (fccmc[\"Date\"] < fccmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "fccmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=fccmc[fccmc[\"Date\"] == fccmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=fccmc[fccmc[\"Date\"] == fccmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "fccmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=fccmc[(fccmc[\"Date\"]>\"2013-11-01\") & (fccmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fccmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=fccmc[(fccmc[\"Date\"]>\"2014-05-01\") & (fccmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "fccmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=fccmc[(fccmc[\"Date\"]>\"2014-08-01\") & (fccmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "fccmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "fermc=pd.read_csv(\"/users/jorge/downloads/fermc.csv\")\n",
    "\n",
    "fermc[\"Date\"] = pd.to_datetime(fermc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "fermc_options=nov_opt[nov_opt['CODE'].str.contains(\"FER\")]\n",
    "fermc_options[\"money\"]= fermc_options[\"STRIKE\"] - fermc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=fermc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=fermc[(fermc[\"Date\"] > fermc_options[\"DATE\"].iloc[i]) & (fermc[\"Date\"] < fermc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "fermc_options[\"MIN\"]=sanvrai\n",
    "fermc_optionsdate= fermc_options[fermc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=fermc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=fermc[(fermc[\"Date\"] > fermc_optionsdate[\"DATE\"].iloc[i]) & (fermc[\"Date\"] < fermc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "fermc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=fermc[fermc[\"Date\"] == fermc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=fermc[fermc[\"Date\"] == fermc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "fermc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=fermc[(fermc[\"Date\"]>\"2013-11-01\") & (fermc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fermc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=fermc[(fermc[\"Date\"]>\"2014-05-01\") & (fermc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "fermc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=fermc[(fermc[\"Date\"]>\"2014-08-01\") & (fermc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "fermc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "gammc=pd.read_csv(\"/users/jorge/downloads/gammc.csv\")\n",
    "\n",
    "gammc[\"Date\"] = pd.to_datetime(gammc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "gammc_options=nov_opt[nov_opt['CODE'].str.contains(\"CGAM\")]\n",
    "gammc_options[\"money\"]= gammc_options[\"STRIKE\"] - gammc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=gammc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=gammc[(gammc[\"Date\"] > gammc_options[\"DATE\"].iloc[i]) & (gammc[\"Date\"] < gammc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "gammc_options[\"MIN\"]=sanvrai\n",
    "gammc_optionsdate= gammc_options[gammc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=gammc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=gammc[(gammc[\"Date\"] > gammc_optionsdate[\"DATE\"].iloc[i]) & (gammc[\"Date\"] < gammc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "gammc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=gammc[gammc[\"Date\"] == gammc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=gammc[gammc[\"Date\"] == gammc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "gammc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=gammc[(gammc[\"Date\"]>\"2013-11-01\") & (gammc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gammc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=gammc[(gammc[\"Date\"]>\"2014-05-01\") & (gammc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "gammc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=gammc[(gammc[\"Date\"]>\"2014-08-01\") & (gammc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "gammc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "gasmc=pd.read_csv(\"/users/jorge/downloads/gasmc.csv\")\n",
    "\n",
    "gasmc[\"Date\"] = pd.to_datetime(gasmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "gasmc_options=nov_opt[nov_opt['CODE'].str.contains(\"GAS\")]\n",
    "gasmc_options[\"money\"]= gasmc_options[\"STRIKE\"] - gasmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=gasmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=gasmc[(gasmc[\"Date\"] > gasmc_options[\"DATE\"].iloc[i]) & (gasmc[\"Date\"] < gasmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "gasmc_options[\"MIN\"]=sanvrai\n",
    "gasmc_optionsdate= gasmc_options[gasmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=gasmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=gasmc[(gasmc[\"Date\"] > gasmc_optionsdate[\"DATE\"].iloc[i]) & (gasmc[\"Date\"] < gasmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "gasmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=gasmc[gasmc[\"Date\"] == gasmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=gasmc[gasmc[\"Date\"] == gasmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "gasmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=gasmc[(gasmc[\"Date\"]>\"2013-11-01\") & (gasmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gasmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=gasmc[(gasmc[\"Date\"]>\"2014-05-01\") & (gasmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "gasmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=gasmc[(gasmc[\"Date\"]>\"2014-08-01\") & (gasmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "gasmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "grfmc=pd.read_csv(\"/users/jorge/downloads/grfmc.csv\")\n",
    "\n",
    "grfmc[\"Date\"] = pd.to_datetime(grfmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "grfmc_options=nov_opt[nov_opt['CODE'].str.contains(\"GFR\")]\n",
    "grfmc_options[\"money\"]= grfmc_options[\"STRIKE\"] - grfmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=grfmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=grfmc[(grfmc[\"Date\"] > grfmc_options[\"DATE\"].iloc[i]) & (grfmc[\"Date\"] < grfmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "grfmc_options[\"MIN\"]=sanvrai\n",
    "grfmc_optionsdate= grfmc_options[grfmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=grfmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=grfmc[(grfmc[\"Date\"] > grfmc_optionsdate[\"DATE\"].iloc[i]) & (grfmc[\"Date\"] < grfmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "grfmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=grfmc[grfmc[\"Date\"] == grfmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=grfmc[grfmc[\"Date\"] == grfmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "grfmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=grfmc[(grfmc[\"Date\"]>\"2013-11-01\") & (grfmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grfmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=grfmc[(grfmc[\"Date\"]>\"2014-05-01\") & (grfmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "grfmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=grfmc[(grfmc[\"Date\"]>\"2014-08-01\") & (grfmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "grfmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "iagmc=pd.read_csv(\"/users/jorge/downloads/iagmc.csv\")\n",
    "\n",
    "iagmc[\"Date\"] = pd.to_datetime(iagmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "iagmc_options=nov_opt[nov_opt['CODE'].str.contains(\"IAG\")]\n",
    "iagmc_options[\"money\"]= iagmc_options[\"STRIKE\"] - iagmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=iagmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=iagmc[(iagmc[\"Date\"] > iagmc_options[\"DATE\"].iloc[i]) & (iagmc[\"Date\"] < iagmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "iagmc_options[\"MIN\"]=sanvrai\n",
    "iagmc_optionsdate= iagmc_options[iagmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=iagmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=iagmc[(iagmc[\"Date\"] > iagmc_optionsdate[\"DATE\"].iloc[i]) & (iagmc[\"Date\"] < iagmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "iagmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=iagmc[iagmc[\"Date\"] == iagmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=iagmc[iagmc[\"Date\"] == iagmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "iagmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=iagmc[(iagmc[\"Date\"]>\"2013-11-01\") & (iagmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "iagmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=iagmc[(iagmc[\"Date\"]>\"2014-05-01\") & (iagmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "iagmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=iagmc[(iagmc[\"Date\"]>\"2014-08-01\") & (iagmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "iagmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "idrmc=pd.read_csv(\"/users/jorge/downloads/idrmc.csv\")\n",
    "\n",
    "idrmc[\"Date\"] = pd.to_datetime(idrmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "idrmc_options=nov_opt[nov_opt['CODE'].str.contains(\"IDR\")]\n",
    "idrmc_options[\"money\"]= idrmc_options[\"STRIKE\"] - idrmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=idrmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=idrmc[(idrmc[\"Date\"] > idrmc_options[\"DATE\"].iloc[i]) & (idrmc[\"Date\"] < idrmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "idrmc_options[\"MIN\"]=sanvrai\n",
    "idrmc_optionsdate= idrmc_options[idrmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=idrmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=idrmc[(idrmc[\"Date\"] > idrmc_optionsdate[\"DATE\"].iloc[i]) & (idrmc[\"Date\"] < idrmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "idrmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=idrmc[idrmc[\"Date\"] == idrmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=idrmc[idrmc[\"Date\"] == idrmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "idrmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=idrmc[(idrmc[\"Date\"]>\"2013-11-01\") & (idrmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "idrmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=idrmc[(idrmc[\"Date\"]>\"2014-05-01\") & (idrmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "idrmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=idrmc[(idrmc[\"Date\"]>\"2014-08-01\") & (idrmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "idrmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "itxmc=pd.read_csv(\"/users/jorge/downloads/itxmc.csv\")\n",
    "\n",
    "itxmc[\"Date\"] = pd.to_datetime(itxmc[\"Date\"],format='%y-%m-%d')\n",
    "\n",
    "itxmc_options=nov_opt[nov_opt['CODE'].str.contains(\"ITX\")]\n",
    "itxmc_options[\"money\"]= itxmc_options[\"STRIKE\"] - itxmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=itxmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=itxmc[(itxmc[\"Date\"] > itxmc_options[\"DATE\"].iloc[i]) & (itxmc[\"Date\"] < itxmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "itxmc_options[\"MIN\"]=sanvrai\n",
    "itxmc_optionsdate= itxmc_options[itxmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=itxmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=itxmc[(itxmc[\"Date\"] > itxmc_optionsdate[\"DATE\"].iloc[i]) & (itxmc[\"Date\"] < itxmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "itxmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=itxmc[itxmc[\"Date\"] == itxmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=itxmc[itxmc[\"Date\"] == itxmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "itxmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=itxmc[(itxmc[\"Date\"]>\"2013-11-01\") & (itxmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "itxmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=itxmc[(itxmc[\"Date\"]>\"2014-05-01\") & (itxmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "itxmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=itxmc[(itxmc[\"Date\"]>\"2014-08-01\") & (itxmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "itxmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "mapmc=pd.read_csv(\"/users/jorge/downloads/mapmc.csv\")\n",
    "\n",
    "mapmc[\"Date\"] = pd.to_datetime(mapmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "mapmc_options=nov_opt[nov_opt['CODE'].str.contains(\"MAP\")]\n",
    "mapmc_options[\"money\"]= mapmc_options[\"STRIKE\"] - mapmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=mapmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=mapmc[(mapmc[\"Date\"] > mapmc_options[\"DATE\"].iloc[i]) & (mapmc[\"Date\"] < mapmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "mapmc_options[\"MIN\"]=sanvrai\n",
    "mapmc_optionsdate= mapmc_options[mapmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=mapmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=mapmc[(mapmc[\"Date\"] > mapmc_optionsdate[\"DATE\"].iloc[i]) & (mapmc[\"Date\"] < mapmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "mapmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=mapmc[mapmc[\"Date\"] == mapmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=mapmc[mapmc[\"Date\"] == mapmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "mapmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=mapmc[(mapmc[\"Date\"]>\"2013-11-01\") & (mapmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mapmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=mapmc[(mapmc[\"Date\"]>\"2014-05-01\") & (mapmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "mapmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=mapmc[(mapmc[\"Date\"]>\"2014-08-01\") & (mapmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "mapmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "mtsmc=pd.read_csv(\"/users/jorge/downloads/mtsmc.csv\")\n",
    "\n",
    "mtsmc[\"Date\"] = pd.to_datetime(mtsmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "mtsmc_options=nov_opt[nov_opt['CODE'].str.contains(\"MTS\")]\n",
    "mtsmc_options[\"money\"]= mtsmc_options[\"STRIKE\"] - mtsmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=mtsmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=mtsmc[(mtsmc[\"Date\"] > mtsmc_options[\"DATE\"].iloc[i]) & (mtsmc[\"Date\"] < mtsmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "mtsmc_options[\"MIN\"]=sanvrai\n",
    "mtsmc_optionsdate= mtsmc_options[mtsmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=mtsmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=mtsmc[(mtsmc[\"Date\"] > mtsmc_optionsdate[\"DATE\"].iloc[i]) & (mtsmc[\"Date\"] < mtsmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "mtsmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=mtsmc[mtsmc[\"Date\"] == mtsmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=mtsmc[mtsmc[\"Date\"] == mtsmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "mtsmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=mtsmc[(mtsmc[\"Date\"]>\"2013-11-01\") & (mtsmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mtsmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=mtsmc[(mtsmc[\"Date\"]>\"2014-05-01\") & (mtsmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "mtsmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=mtsmc[(mtsmc[\"Date\"]>\"2014-08-01\") & (mtsmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "mtsmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "ohlmc=pd.read_csv(\"/users/jorge/downloads/ohlmc.csv\")\n",
    "\n",
    "ohlmc[\"Date\"] = pd.to_datetime(ohlmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "ohlmc_options=nov_opt[nov_opt['CODE'].str.contains(\"OHL\")]\n",
    "ohlmc_options[\"money\"]= ohlmc_options[\"STRIKE\"] - ohlmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=ohlmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=ohlmc[(ohlmc[\"Date\"] > ohlmc_options[\"DATE\"].iloc[i]) & (ohlmc[\"Date\"] < ohlmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "ohlmc_options[\"MIN\"]=sanvrai\n",
    "ohlmc_optionsdate= ohlmc_options[ohlmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=ohlmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=ohlmc[(ohlmc[\"Date\"] > ohlmc_optionsdate[\"DATE\"].iloc[i]) & (ohlmc[\"Date\"] < ohlmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "ohlmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=ohlmc[ohlmc[\"Date\"] == ohlmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=ohlmc[ohlmc[\"Date\"] == ohlmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "ohlmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=ohlmc[(ohlmc[\"Date\"]>\"2013-11-01\") & (ohlmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ohlmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=ohlmc[(ohlmc[\"Date\"]>\"2014-05-01\") & (ohlmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "ohlmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=ohlmc[(ohlmc[\"Date\"]>\"2014-08-01\") & (ohlmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "ohlmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "popmc=pd.read_csv(\"/users/jorge/downloads/popmc.csv\")\n",
    "\n",
    "popmc[\"Date\"] = pd.to_datetime(popmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "popmc_options=nov_opt[nov_opt['CODE'].str.contains(\"POP\")]\n",
    "popmc_options[\"money\"]= popmc_options[\"STRIKE\"] - popmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=popmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=popmc[(popmc[\"Date\"] > popmc_options[\"DATE\"].iloc[i]) & (popmc[\"Date\"] < popmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "popmc_options[\"MIN\"]=sanvrai\n",
    "popmc_optionsdate= popmc_options[popmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=popmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=popmc[(popmc[\"Date\"] > popmc_optionsdate[\"DATE\"].iloc[i]) & (popmc[\"Date\"] < popmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "popmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=popmc[popmc[\"Date\"] == popmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=popmc[popmc[\"Date\"] == popmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "popmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=popmc[(popmc[\"Date\"]>\"2013-11-01\") & (popmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "popmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=popmc[(popmc[\"Date\"]>\"2014-05-01\") & (popmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "popmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=popmc[(popmc[\"Date\"]>\"2014-08-01\") & (popmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "popmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "reemc=pd.read_csv(\"/users/jorge/downloads/reemc.csv\")\n",
    "\n",
    "reemc[\"Date\"] = pd.to_datetime(reemc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "reemc_options=nov_opt[nov_opt['CODE'].str.contains(\"REE\")]\n",
    "reemc_options[\"money\"]= reemc_options[\"STRIKE\"] - reemc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=reemc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=reemc[(reemc[\"Date\"] > reemc_options[\"DATE\"].iloc[i]) & (reemc[\"Date\"] < reemc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "reemc_options[\"MIN\"]=sanvrai\n",
    "reemc_optionsdate= reemc_options[reemc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=reemc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=reemc[(reemc[\"Date\"] > reemc_optionsdate[\"DATE\"].iloc[i]) & (reemc[\"Date\"] < reemc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "reemc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=reemc[reemc[\"Date\"] == reemc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=reemc[reemc[\"Date\"] == reemc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "reemc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=reemc[(reemc[\"Date\"]>\"2013-11-01\") & (reemc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reemc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=reemc[(reemc[\"Date\"]>\"2014-05-01\") & (reemc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "reemc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=reemc[(reemc[\"Date\"]>\"2014-08-01\") & (reemc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "reemc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "repmc=pd.read_csv(\"/users/jorge/downloads/repmc.csv\")\n",
    "\n",
    "repmc[\"Date\"] = pd.to_datetime(repmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "repmc_options=nov_opt[nov_opt['CODE'].str.contains(\"REP\")]\n",
    "repmc_options[\"money\"]= repmc_options[\"STRIKE\"] - repmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=repmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=repmc[(repmc[\"Date\"] > repmc_options[\"DATE\"].iloc[i]) & (repmc[\"Date\"] < repmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "repmc_options[\"MIN\"]=sanvrai\n",
    "repmc_optionsdate= repmc_options[repmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=repmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=repmc[(repmc[\"Date\"] > repmc_optionsdate[\"DATE\"].iloc[i]) & (repmc[\"Date\"] < repmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "repmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=repmc[repmc[\"Date\"] == repmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=repmc[repmc[\"Date\"] == repmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "repmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=repmc[(repmc[\"Date\"]>\"2013-11-01\") & (repmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "repmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=repmc[(repmc[\"Date\"]>\"2014-05-01\") & (repmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "repmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=repmc[(repmc[\"Date\"]>\"2014-08-01\") & (repmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "repmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "sabmc=pd.read_csv(\"/users/jorge/downloads/sabmc.csv\")\n",
    "\n",
    "sabmc[\"Date\"] = pd.to_datetime(sabmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "sabmc_options=nov_opt[nov_opt['CODE'].str.contains(\"SAB\")]\n",
    "sabmc_options[\"money\"]= sabmc_options[\"STRIKE\"] - sabmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=sabmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=sabmc[(sabmc[\"Date\"] > sabmc_options[\"DATE\"].iloc[i]) & (sabmc[\"Date\"] < sabmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "sabmc_options[\"MIN\"]=sanvrai\n",
    "sabmc_optionsdate= sabmc_options[sabmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=sabmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=sabmc[(sabmc[\"Date\"] > sabmc_optionsdate[\"DATE\"].iloc[i]) & (sabmc[\"Date\"] < sabmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "sabmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=sabmc[sabmc[\"Date\"] == sabmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=sabmc[sabmc[\"Date\"] == sabmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "sabmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=sabmc[(sabmc[\"Date\"]>\"2013-11-01\") & (sabmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sabmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=sabmc[(sabmc[\"Date\"]>\"2014-05-01\") & (sabmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "sabmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=sabmc[(sabmc[\"Date\"]>\"2014-08-01\") & (sabmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "sabmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "sanmc=pd.read_csv(\"/users/jorge/downloads/sanmc.csv\")\n",
    "\n",
    "sanmc[\"Date\"] = pd.to_datetime(sanmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "sanmc_options=nov_opt[nov_opt['CODE'].str.contains(\"CSAN\")]\n",
    "sanmc_options[\"money\"]= sanmc_options[\"STRIKE\"] - sanmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=sanmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=sanmc[(sanmc[\"Date\"] > sanmc_options[\"DATE\"].iloc[i]) & (sanmc[\"Date\"] < sanmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "sanmc_options[\"MIN\"]=sanvrai\n",
    "sanmc_optionsdate= sanmc_options[sanmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=sanmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=sanmc[(sanmc[\"Date\"] > sanmc_optionsdate[\"DATE\"].iloc[i]) & (sanmc[\"Date\"] < sanmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "sanmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=sanmc[sanmc[\"Date\"] == sanmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=sanmc[sanmc[\"Date\"] == sanmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "sanmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=sanmc[(sanmc[\"Date\"]>\"2013-11-01\") & (sanmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=sanmc[(sanmc[\"Date\"]>\"2014-05-01\") & (sanmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "sanmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=sanmc[(sanmc[\"Date\"]>\"2014-08-01\") & (sanmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "sanmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "svomc=pd.read_csv(\"/users/jorge/downloads/svomc.csv\")\n",
    "\n",
    "svomc[\"Date\"] = pd.to_datetime(svomc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "svomc_options=nov_opt[nov_opt['CODE'].str.contains(\"SVO\")]\n",
    "svomc_options[\"money\"]= svomc_options[\"STRIKE\"] - svomc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=svomc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=svomc[(svomc[\"Date\"] > svomc_options[\"DATE\"].iloc[i]) & (svomc[\"Date\"] < svomc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "svomc_options[\"MIN\"]=sanvrai\n",
    "svomc_optionsdate= svomc_options[svomc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=svomc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=svomc[(svomc[\"Date\"] > svomc_optionsdate[\"DATE\"].iloc[i]) & (svomc[\"Date\"] < svomc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "svomc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=svomc[svomc[\"Date\"] == svomc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=svomc[svomc[\"Date\"] == svomc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "svomc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=svomc[(svomc[\"Date\"]>\"2013-11-01\") & (svomc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "svomc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=svomc[(svomc[\"Date\"]>\"2014-05-01\") & (svomc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "svomc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=svomc[(svomc[\"Date\"]>\"2014-08-01\") & (svomc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "svomc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "tefmc=pd.read_csv(\"/users/jorge/downloads/tefmc.csv\")\n",
    "\n",
    "tefmc[\"Date\"] = pd.to_datetime(tefmc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "tefmc_options=nov_opt[nov_opt['CODE'].str.contains(\"TEF\")]\n",
    "tefmc_options[\"money\"]= tefmc_options[\"STRIKE\"] - tefmc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=tefmc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=tefmc[(tefmc[\"Date\"] > tefmc_options[\"DATE\"].iloc[i]) & (tefmc[\"Date\"] < tefmc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "tefmc_options[\"MIN\"]=sanvrai\n",
    "tefmc_optionsdate= tefmc_options[tefmc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=tefmc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=tefmc[(tefmc[\"Date\"] > tefmc_optionsdate[\"DATE\"].iloc[i]) & (tefmc[\"Date\"] < tefmc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "tefmc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=tefmc[tefmc[\"Date\"] == tefmc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=tefmc[tefmc[\"Date\"] == tefmc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "tefmc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=tefmc[(tefmc[\"Date\"]>\"2013-11-01\") & (tefmc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tefmc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=tefmc[(tefmc[\"Date\"]>\"2014-05-01\") & (tefmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "tefmc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=tefmc[(tefmc[\"Date\"]>\"2014-08-01\") & (tefmc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "tefmc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "tremc=pd.read_csv(\"/users/jorge/downloads/tremc.csv\")\n",
    "\n",
    "tremc[\"Date\"] = pd.to_datetime(tremc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "tremc_options=nov_opt[nov_opt['CODE'].str.contains(\"TRE\")]\n",
    "tremc_options[\"money\"]= tremc_options[\"STRIKE\"] - tremc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=tremc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=tremc[(tremc[\"Date\"] > tremc_options[\"DATE\"].iloc[i]) & (tremc[\"Date\"] < tremc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "tremc_options[\"MIN\"]=sanvrai\n",
    "tremc_optionsdate= tremc_options[tremc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=tremc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=tremc[(tremc[\"Date\"] > tremc_optionsdate[\"DATE\"].iloc[i]) & (tremc[\"Date\"] < tremc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "tremc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=tremc[tremc[\"Date\"] == tremc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=tremc[tremc[\"Date\"] == tremc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "tremc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=tremc[(tremc[\"Date\"]>\"2013-11-01\") & (tremc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tremc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=tremc[(tremc[\"Date\"]>\"2014-05-01\") & (tremc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "tremc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=tremc[(tremc[\"Date\"]>\"2014-08-01\") & (tremc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "tremc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "\n",
    "vismc=pd.read_csv(\"/users/jorge/downloads/vismc.csv\")\n",
    "\n",
    "vismc[\"Date\"] = pd.to_datetime(vismc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "vismc_options=nov_opt[nov_opt['CODE'].str.contains(\"VIS\")]\n",
    "vismc_options[\"money\"]= vismc_options[\"STRIKE\"] - vismc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=vismc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=vismc[(vismc[\"Date\"] > vismc_options[\"DATE\"].iloc[i]) & (vismc[\"Date\"] < vismc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"High\"].max())\n",
    "\n",
    "vismc_options[\"MIN\"]=sanvrai\n",
    "vismc_optionsdate= vismc_options[vismc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=vismc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=vismc[(vismc[\"Date\"] > vismc_optionsdate[\"DATE\"].iloc[i]) & (vismc[\"Date\"] < vismc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"High\"].std())\n",
    "vismc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=vismc[vismc[\"Date\"] == vismc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=vismc[vismc[\"Date\"] == vismc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Open\"].iloc[1] - gain[\"Close\"].iloc[0]) / gain[\"Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "vismc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=vismc[(vismc[\"Date\"]>\"2013-11-01\") & (vismc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"High\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vismc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=vismc[(vismc[\"Date\"]>\"2014-05-01\") & (vismc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"High\"].std())\n",
    "vismc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=vismc[(vismc[\"Date\"]>\"2014-08-01\") & (vismc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"High\"].std())\n",
    "vismc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ibemc=pd.read_csv(\"/users/jorge/downloads/ibemc.csv\")\n",
    "\n",
    "ibemc[\"Date\"] = pd.to_datetime(ibemc[\"Date\"],format='%Y-%m-%d')\n",
    "\n",
    "ibemc_options=nov_opt[nov_opt['CODE'].str.contains(\"IBE\")]\n",
    "ibemc_options[\"money\"]= ibemc_options[\"STRIKE\"] - ibemc_options[\"LIQ\"]\n",
    "\n",
    "sanvrai=[]\n",
    "n=ibemc_options.shape[0]\n",
    "for i in range(0,n):\n",
    "    san=ibemc[(ibemc[\"Date\"] > ibemc_options[\"DATE\"].iloc[i]) & (ibemc[\"Date\"] < ibemc_options[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanvrai.append(san[\"Adj Close\"].max())\n",
    "\n",
    "ibemc_options[\"MIN\"]=sanvrai\n",
    "ibemc_optionsdate= ibemc_options[ibemc_options[\"STRIKE_DATE\"]<\"2016-11-30\"]\n",
    "\n",
    "sanai=[]\n",
    "n=ibemc_optionsdate.shape[0]\n",
    "for i in range(0,n):\n",
    "    sant=ibemc[(ibemc[\"Date\"] > ibemc_optionsdate[\"DATE\"].iloc[i]) & (ibemc[\"Date\"] < ibemc_optionsdate[\"STRIKE_DATE\"].iloc[i])]\n",
    "    sanai.append(sant[\"Adj Close\"].std())\n",
    "ibemc_optionsdate[\"STD\"]=sanai\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sanper=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    santi=ibemc[ibemc[\"Date\"] == ibemc_optionsdate[\"DATE\"].iloc[i]]\n",
    "    santo=ibemc[ibemc[\"Date\"] == ibemc_optionsdate[\"STRIKE_DATE\"].iloc[i]]\n",
    "    frames=[santi,santo]\n",
    "    gain = pd.concat(frames)\n",
    "    income= (gain[\"Adj Close\"].iloc[1] - gain[\"Adj Close\"].iloc[0]) / gain[\"Adj Close\"].iloc[0]\n",
    "    sanper.append(income)\n",
    "\n",
    "ibemc_optionsdate[\"GAIN\"]=sanper\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "old=ibemc[(ibemc[\"Date\"]>\"2013-11-01\") & (ibemc[\"Date\"]<\"2014-11-01\")]\n",
    "oldie=[]\n",
    "for i in range(0,n):\n",
    "    oldie.append(old[\"Adj Close\"].std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ibemc_optionsdate[\"1ySTD\"]=oldie\n",
    "\n",
    "\n",
    "old6=ibemc[(ibemc[\"Date\"]>\"2014-05-01\") & (ibemc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie6=[]\n",
    "for i in range(0,n):\n",
    "    oldie6.append(old6[\"Adj Close\"].std())\n",
    "ibemc_optionsdate[\"6mSTD\"]=oldie6\n",
    "\n",
    "old3=ibemc[(ibemc[\"Date\"]>\"2014-08-01\") & (ibemc[\"Date\"]<\"2014-11-01\")]\n",
    "\n",
    "oldie3=[]\n",
    "for i in range(0,n):\n",
    "    oldie3.append(old3[\"Adj Close\"].std())\n",
    "ibemc_optionsdate[\"3mSTD\"]=oldie3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCAT AND NEW CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "frames = [abbmc_optionsdate, abemc_optionsdate, acsmc_optionsdate, acxmc_optionsdate, amsmc_optionsdate, anamc_optionsdate, anamc_optionsdate, bbvamc_optionsdate, bkiamc_optionsdate, bktmc_optionsdate, bmemc_optionsdate, cabmc_optionsdate, ebrmc_optionsdate, elemc_optionsdate, enamc_optionsdate, fccmc_optionsdate, fermc_optionsdate, gammc_optionsdate, gasmc_optionsdate, grfmc_optionsdate, iagmc_optionsdate, ibemc_optionsdate, idrmc_optionsdate, itxmc_optionsdate, mapmc_optionsdate, mtsmc_optionsdate, ohlmc_optionsdate, popmc_optionsdate, reemc_optionsdate, repmc_optionsdate, sabmc_optionsdate, sanmc_optionsdate, svomc_optionsdate, tefmc_optionsdate, tremc_optionsdate, vismc_optionsdate]\n",
    "\n",
    "result14 = pd.concat(frames)\n",
    "result14[\"MAX\"]=result14[\"MIN\"]\n",
    "\n",
    "final_clean=result14[[\"DATE\", \"CODE\", \"STRIKE\", \"STRIKE_DATE\", \"LIQ\", \"VOLATILITY\", \"DELTA\", \"VOLUME\",\"GAIN\", \"money\", \"MAX\", \"STD\",\"1ySTD\",\"6mSTD\",\"3mSTD\"]]\n",
    "\n",
    "new_final = final_clean.dropna()\n",
    "\n",
    "company=new_final[\"CODE\"]\n",
    "\n",
    "comp=[]\n",
    "for row in company:\n",
    "    name=row[1:4]\n",
    "    comp.append(name)\n",
    "\n",
    "    \n",
    "new_final[\"TARGET\"]=new_final[\"STRIKE\"]+ new_final[\"LIQ\"]   \n",
    "\n",
    "new_final[\"COMPANY\"]=comp\n",
    "\n",
    "new_final[\"PREMIUM\"]=new_final[\"LIQ\"]/ (new_final[\"STRIKE\"])\n",
    "\n",
    "\n",
    "put_final = new_final.dropna()\n",
    "\n",
    "success=[]\n",
    "n=put_final.shape[0]\n",
    "for i in range(0,n) :\n",
    "    if put_final[\"TARGET\"].iloc[i]< put_final[\"MAX\"].iloc[i]:\n",
    "        success.append(1)\n",
    "    else:\n",
    "        success.append(0)\n",
    "put_final[\"TRIGGER\"]=success\n",
    "\n",
    "net=[]\n",
    "n=put_final.shape[0]\n",
    "for i in range(0,n) :\n",
    "    if put_final[\"TRIGGER\"].iloc[i]==1:\n",
    "        net.append(put_final[\"MAX\"].iloc[i]-put_final[\"TARGET\"].iloc[i])\n",
    "    else:\n",
    "        net.append((put_final[\"LIQ\"].iloc[i])*(-1))\n",
    "put_final[\"NET\"]=net\n",
    "\n",
    "put_final[\"ROI\"]=put_final[\"NET\"] / put_final[\"LIQ\"] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "diff=put_final[\"STRIKE_DATE\"]-put_final[\"DATE\"]\n",
    "\n",
    "days=diff.astype(int)/86400000000000\n",
    "days=days.astype(int)\n",
    "put_final[\"DAYS\"]=days\n",
    "\n",
    "put=put_final[[\"COMPANY\",\"DATE\", \"CODE\", \"STRIKE\", \"STRIKE_DATE\", \"DAYS\",\"LIQ\", \"VOLATILITY\", \"DELTA\", \"VOLUME\", \"TARGET\", \"MAX\", \"GAIN\", \"TRIGGER\", \"NET\",\"ROI\", \"PREMIUM\", \"STD\", \"1ySTD\",\"6mSTD\",\"3mSTD\"]]\n",
    "\n",
    "deltas=[]\n",
    "n=put.shape[0]\n",
    "for i in range(0,n) :\n",
    "    if put[\"DELTA\"].iloc[i]<(0.2):\n",
    "        deltas.append(1)\n",
    "    elif (put[\"DELTA\"].iloc[i]>=(0.2)) & (put[\"DELTA\"].iloc[i]<(0.4)):\n",
    "        deltas.append(2)\n",
    "    elif (put[\"DELTA\"].iloc[i]>=(0.4)) & (put[\"DELTA\"].iloc[i]<(0.6)):\n",
    "        deltas.append(3)\n",
    "    elif (put[\"DELTA\"].iloc[i]>=(0.6)) & (put[\"DELTA\"].iloc[i]<(0.8)):\n",
    "        deltas.append(4)\n",
    "    else:\n",
    "        deltas.append(5)\n",
    "\n",
    "\n",
    "put[\"HIGH DELTA\"]=deltas\n",
    "\n",
    "vols=[]\n",
    "n=put.shape[0]\n",
    "for i in range(0,n) :\n",
    "    if put[\"VOLATILITY\"].iloc[i]<(20):\n",
    "        vols.append(1)\n",
    "    elif (put[\"VOLATILITY\"].iloc[i]>=(20)) & (put[\"VOLATILITY\"].iloc[i]<(25)):\n",
    "        vols.append(2)\n",
    "    elif (put[\"VOLATILITY\"].iloc[i]>=(25)) & (put[\"VOLATILITY\"].iloc[i]<(30)):\n",
    "        vols.append(3)\n",
    "    elif (put[\"VOLATILITY\"].iloc[i]>=(30)) & (put[\"VOLATILITY\"].iloc[i]<(35)):\n",
    "        vols.append(4)\n",
    "    else:\n",
    "        vols.append(5)\n",
    "put[\"HIGH VOL\"]=vols\n",
    "\n",
    "prem=[]\n",
    "n=put.shape[0]\n",
    "for i in range(0,n) :\n",
    "    if put[\"PREMIUM\"].iloc[i]<(0.01):\n",
    "        prem.append(1)\n",
    "    elif (put[\"PREMIUM\"].iloc[i]>=(0.01)) & (put[\"PREMIUM\"].iloc[i]<(0.02)):\n",
    "        prem.append(2)\n",
    "    elif (put[\"PREMIUM\"].iloc[i]>=(0.02)) & (put[\"PREMIUM\"].iloc[i]<(0.04)):\n",
    "        prem.append(3)\n",
    "    elif (put[\"PREMIUM\"].iloc[i]>=(0.04)) & (put[\"PREMIUM\"].iloc[i]<(0.07)):\n",
    "        prem.append(4)\n",
    "    else:\n",
    "        prem.append(5)\n",
    "\n",
    "\n",
    "put[\"HIGH PREM\"]=prem\n",
    "\n",
    "day=[]\n",
    "n=put.shape[0]\n",
    "for i in range(0,n) :\n",
    "    if put[\"DAYS\"].iloc[i]<(30):\n",
    "        day.append(1)\n",
    "    elif (put[\"DAYS\"].iloc[i]>=(30)) & (put[\"DAYS\"].iloc[i]<(60)):\n",
    "        day.append(2)\n",
    "    elif (put[\"DAYS\"].iloc[i]>=(60)) & (put[\"DAYS\"].iloc[i]<(90)):\n",
    "        day.append(3)\n",
    "    elif (put[\"DAYS\"].iloc[i]>=(90)) & (put[\"DAYS\"].iloc[i]<(120)):\n",
    "        day.append(4)\n",
    "    else:\n",
    "        day.append(5)\n",
    "\n",
    "put[\"DURATION\"]=day\n",
    "\n",
    "put_novdet=put[[\"COMPANY\", \"CODE\",\"DATE\", \"STRIKE\", \"STRIKE_DATE\", \"DAYS\", \"LIQ\", \"VOLUME\",\"DELTA\", \"VOLATILITY\", \"MAX\",\"TARGET\", \"TRIGGER\", \"NET\", \"ROI\", \"PREMIUM\", \"GAIN\",\"STD\", \"1ySTD\",\"6mSTD\", \"3mSTD\", \"HIGH DELTA\", \"HIGH VOL\", \"HIGH PREM\", \"DURATION\" ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE AND LOAD FIRST VERSION OF put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "put_novdet.to_csv(\"/users/jorge/calloptgainstd.csv\")\n",
    "put=pd.read_csv(\"/users/jorge/calloptgainstd.csv\")\n",
    "put=put[['COMPANY', 'CODE', 'DATE', 'STRIKE', 'STRIKE_DATE',\n",
    "       'DAYS', 'LIQ', 'VOLUME', 'DELTA', 'VOLATILITY', 'MAX', 'TARGET',\n",
    "       'TRIGGER', 'NET', 'ROI', 'PREMIUM', 'GAIN', 'STD', '1ySTD', '6mSTD',\n",
    "       '3mSTD', 'HIGH DELTA', 'HIGH VOL', 'HIGH PREM', 'DURATION']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE CIA TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "companies=Series(put[\"NET\"].values, index=put[\"COMPANY\"])\n",
    "put_table=put.pivot_table(index=\"COMPANY\", values=\"NET\")\n",
    "\n",
    "import numpy as np\n",
    "put_net=put.pivot_table(index=\"COMPANY\", values=\"NET\", aggfunc=np.sum)\n",
    "\n",
    "put_trigger=put.pivot_table(index=\"COMPANY\", values=\"TRIGGER\")\n",
    "\n",
    "put_vol=put.pivot_table(index=\"COMPANY\", values=\"VOLATILITY\")\n",
    "put_prem=put.pivot_table(index=\"COMPANY\", values=\"PREMIUM\")\n",
    "put_std=put.pivot_table(index=\"COMPANY\", values=\"STD\")\n",
    "put_1std=put.pivot_table(index=\"COMPANY\", values=\"1ySTD\")\n",
    "put_6mstd=put.pivot_table(index=\"COMPANY\", values=\"6mSTD\")\n",
    "put_3mstd=put.pivot_table(index=\"COMPANY\", values=\"3mSTD\")\n",
    "put_gain=put.pivot_table(index=\"COMPANY\", values=\"GAIN\")\n",
    "\n",
    "\n",
    "put_df=pd.DataFrame(put_table)\n",
    "\n",
    "put_df[\"sumNET\"]=put_net\n",
    "put_df[\"TRIGGER\"]=put_trigger\n",
    "\n",
    "put_df[\"VOLATILITY\"]=put_vol\n",
    "put_df[\"PREMIUM\"]=put_prem\n",
    "put_df[\"STD\"]=put_std\n",
    "put_df[\"1ySTD\"]=put_1std\n",
    "put_df[\"6mSTD\"]=put_6mstd\n",
    "put_df[\"3mSTD\"]=put_3mstd\n",
    "put_df[\"GAIN\"]=put_gain\n",
    "put_count=put.pivot_table(index=\"COMPANY\", values=\"NET\", aggfunc=np.count_nonzero)\n",
    "put_count=put_count.astype(int)\n",
    "\n",
    "put_df[\"COUNT\"]=put_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE CIAS VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "put_df=put_df.drop(\"GAIN\", axis=1)\n",
    "put_df=put_df.drop(\"STD\", axis=1)\n",
    "put_df.to_csv(\"ciascallnov14.csv\")\n",
    "put.to_csv(\"finalcallnov14.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDENTIFY SECTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "banks=put[(put[\"COMPANY\"]==\"BBV\") | (put[\"COMPANY\"]==\"SAN\") |(put[\"COMPANY\"]==\"POP\")|(put[\"COMPANY\"]==\"BKI\")|(put[\"COMPANY\"]==\"SAB\") |(put[\"COMPANY\"]==\"CAB\")]\n",
    "energy=put[(put[\"COMPANY\"]==\"ELE\") | (put[\"COMPANY\"]==\"ENA\") |(put[\"COMPANY\"]==\"GAS\")|(put[\"COMPANY\"]==\"IBE\")|(put[\"COMPANY\"]==\"REE\")|(put[\"COMPANY\"]==\"REP\")]\n",
    "industry=put[(put[\"COMPANY\"]==\"ABE\") | (put[\"COMPANY\"]==\"ACS\") |(put[\"COMPANY\"]==\"ACX\")|(put[\"COMPANY\"]==\"ANA\")|(put[\"COMPANY\"]==\"FCC\")|(put[\"COMPANY\"]==\"FER\")|(put[\"COMPANY\"]==\"GAM\")|(put[\"COMPANY\"]==\"MTS\")|(put[\"COMPANY\"]==\"OHL\")|(put[\"COMPANY\"]==\"SVO\")|(put[\"COMPANY\"]==\"TRE\")]\n",
    "consumer=put[(put[\"COMPANY\"]==\"ABB\") | (put[\"COMPANY\"]==\"EBR\") |(put[\"COMPANY\"]==\"ITX\")|(put[\"COMPANY\"]==\"VIS\")]\n",
    "services=put[(put[\"COMPANY\"]==\"BME\") | (put[\"COMPANY\"]==\"IAG\")|(put[\"COMPANY\"]==\"MAP\")]\n",
    "tech=put[(put[\"COMPANY\"]==\"AMS\") | (put[\"COMPANY\"]==\"IDR\") |(put[\"COMPANY\"]==\"TEF\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD SECTOR COLUMN TO GENERAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "energia=energy[\"COMPANY\"]\n",
    "comp=[]\n",
    "for row in energia:\n",
    "    \n",
    "    comp.append(\"ENERGY\")\n",
    "energy[\"SECTOR\"]=comp\n",
    "\n",
    "energia=banks[\"COMPANY\"]\n",
    "comp=[]\n",
    "for row in energia:\n",
    "    \n",
    "    comp.append(\"BANKS\")\n",
    "banks[\"SECTOR\"]=comp\n",
    "\n",
    "energia=industry[\"COMPANY\"]\n",
    "comp=[]\n",
    "for row in energia:\n",
    "    \n",
    "    comp.append(\"INDUSTRY\")\n",
    "industry[\"SECTOR\"]=comp\n",
    "\n",
    "energia=services[\"COMPANY\"]\n",
    "comp=[]\n",
    "for row in energia:\n",
    "    \n",
    "    comp.append(\"SERVICES\")\n",
    "services[\"SECTOR\"]=comp\n",
    "\n",
    "energia=consumer[\"COMPANY\"]\n",
    "comp=[]\n",
    "for row in energia:\n",
    "    \n",
    "    comp.append(\"CONSUMER\")\n",
    "consumer[\"SECTOR\"]=comp\n",
    "\n",
    "energia=tech[\"COMPANY\"]\n",
    "comp=[]\n",
    "for row in energia:\n",
    "    \n",
    "    comp.append(\"TECH\")\n",
    "tech[\"SECTOR\"]=comp\n",
    "\n",
    "frames = [banks, energy, tech, consumer, industry, services]\n",
    "industries = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "industries=industries[[\"DATE\", \"CODE\", \"COMPANY\", \"SECTOR\", \"STRIKE\", \"STRIKE_DATE\",\"DAYS\", \"LIQ\", \"VOLATILITY\", \"DELTA\", \"PREMIUM\" ,\"VOLUME\",\"GAIN\",\"TARGET\", \"TRIGGER\", \"NET\", \"ROI\", \"MAX\",\"HIGH DELTA\", \"HIGH PREM\", \"HIGH VOL\", \"DURATION\", \"STD\",\"1ySTD\",\"6mSTD\",\"3mSTD\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE MAIN FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "industries.to_csv(\"sectorcall1114.csv\")\n",
    "sectores=pd.read_csv(\"/users/jorge/sectorcall1114.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE SECTOR TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "sectors=Series(industries[\"NET\"].values, index=industries[\"SECTOR\"])\n",
    "put_table=industries.pivot_table(index=\"SECTOR\", values=\"NET\")\n",
    "\n",
    "import numpy as np\n",
    "put_net=industries.pivot_table(index=\"SECTOR\", values=\"NET\", aggfunc=np.sum)\n",
    "\n",
    "put_trigger=industries.pivot_table(index=\"SECTOR\", values=\"TRIGGER\")\n",
    "\n",
    "put_vol=industries.pivot_table(index=\"SECTOR\", values=\"VOLATILITY\")\n",
    "put_prem=industries.pivot_table(index=\"SECTOR\", values=\"PREMIUM\")\n",
    "put_std=industries.pivot_table(index=\"SECTOR\", values=\"STD\")\n",
    "put_1std=industries.pivot_table(index=\"SECTOR\", values=\"1ySTD\")\n",
    "put_6mstd=industries.pivot_table(index=\"SECTOR\", values=\"6mSTD\")\n",
    "put_3mstd=industries.pivot_table(index=\"SECTOR\", values=\"3mSTD\")\n",
    "\n",
    "put_roi=industries.pivot_table(index=\"SECTOR\", values=\"ROI\")\n",
    "put_roiagg=industries.pivot_table(index=\"SECTOR\", values=\"ROI\", aggfunc=np.sum)\n",
    "put_sector=pd.DataFrame(put_table)\n",
    "\n",
    "put_sector[\"sumNET\"]=put_net\n",
    "put_sector[\"TRIGGER\"]=put_trigger\n",
    "put_sector[\"ROI\"]=put_roi\n",
    "put_sector[\"sumROI\"]=put_roiagg\n",
    "put_sector[\"VOLATILITY\"]=put_vol\n",
    "put_sector[\"PREMIUM\"]=put_prem\n",
    "put_sector[\"STD\"]=put_std\n",
    "put_sector[\"1ySTD\"]=put_1std\n",
    "put_sector[\"6mSTD\"]=put_6mstd\n",
    "put_sector[\"3mSTD\"]=put_3mstd\n",
    "\n",
    "put_count=industries.pivot_table(index=\"SECTOR\", values=\"NET\", aggfunc=np.count_nonzero)\n",
    "put_count=put_count.astype(int)\n",
    "\n",
    "put_sector[\"COUNT\"]=put_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE SECTOR TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "put_sector.to_csv(\"aggsectorcall14.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIMILATE PUT TO PUT_DF (REMEMBER TO UPDATE LATER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "put=put_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE SECTOR COLUMN TO CIAS TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "banks=put[(put[\"COMPANY\"]==\"BBV\") | (put[\"COMPANY\"]==\"SAN\") |(put[\"COMPANY\"]==\"POP\")|(put[\"COMPANY\"]==\"BKI\")|(put[\"COMPANY\"]==\"SAB\") |(put[\"COMPANY\"]==\"CAB\")]\n",
    "energy=put[(put[\"COMPANY\"]==\"ELE\") | (put[\"COMPANY\"]==\"ENA\") |(put[\"COMPANY\"]==\"GAS\")|(put[\"COMPANY\"]==\"IBE\")|(put[\"COMPANY\"]==\"REE\")|(put[\"COMPANY\"]==\"REP\")]\n",
    "industry=put[(put[\"COMPANY\"]==\"ABE\") | (put[\"COMPANY\"]==\"ACS\") |(put[\"COMPANY\"]==\"ACX\")|(put[\"COMPANY\"]==\"ANA\")|(put[\"COMPANY\"]==\"FCC\")|(put[\"COMPANY\"]==\"FER\")|(put[\"COMPANY\"]==\"GAM\")|(put[\"COMPANY\"]==\"MTS\")|(put[\"COMPANY\"]==\"OHL\")|(put[\"COMPANY\"]==\"SVO\")|(put[\"COMPANY\"]==\"TRE\")]\n",
    "consumer=put[(put[\"COMPANY\"]==\"ABB\") | (put[\"COMPANY\"]==\"EBR\") |(put[\"COMPANY\"]==\"ITX\")|(put[\"COMPANY\"]==\"VIS\")]\n",
    "services=put[(put[\"COMPANY\"]==\"BME\") | (put[\"COMPANY\"]==\"IAG\")|(put[\"COMPANY\"]==\"MAP\")]\n",
    "tech=put[(put[\"COMPANY\"]==\"AMS\") | (put[\"COMPANY\"]==\"IDR\") |(put[\"COMPANY\"]==\"TEF\")]\n",
    "energia=energy[\"COMPANY\"]\n",
    "comp=[]\n",
    "for row in energia:\n",
    "    \n",
    "    comp.append(\"ENERGY\")\n",
    "energy[\"SECTOR\"]=comp\n",
    "\n",
    "energia=banks[\"COMPANY\"]\n",
    "comp=[]\n",
    "for row in energia:\n",
    "    \n",
    "    comp.append(\"BANKS\")\n",
    "banks[\"SECTOR\"]=comp\n",
    "\n",
    "energia=industry[\"COMPANY\"]\n",
    "comp=[]\n",
    "for row in energia:\n",
    "    \n",
    "    comp.append(\"INDUSTRY\")\n",
    "industry[\"SECTOR\"]=comp\n",
    "\n",
    "energia=services[\"COMPANY\"]\n",
    "comp=[]\n",
    "for row in energia:\n",
    "    \n",
    "    comp.append(\"SERVICES\")\n",
    "services[\"SECTOR\"]=comp\n",
    "\n",
    "energia=consumer[\"COMPANY\"]\n",
    "comp=[]\n",
    "for row in energia:\n",
    "    \n",
    "    comp.append(\"CONSUMER\")\n",
    "consumer[\"SECTOR\"]=comp\n",
    "\n",
    "energia=tech[\"COMPANY\"]\n",
    "comp=[]\n",
    "for row in energia:\n",
    "    \n",
    "    comp.append(\"TECH\")\n",
    "tech[\"SECTOR\"]=comp\n",
    "\n",
    "frames = [banks, energy, tech, consumer, industry, services]\n",
    "industries = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sectors=industries[['COMPANY','SECTOR', 'NET', 'sumNET', 'TRIGGER', 'VOLATILITY', 'PREMIUM', '1ySTD',\n",
    "       '6mSTD', '3mSTD', 'COUNT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sectors.to_csv(\"ciassectors.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD ROI COLUMN TO CIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "industries=pd.read_csv(\"/users/jorge/sectorcall1114.csv\")\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "put_roi=industries.pivot_table(index=\"COMPANY\", values=\"ROI\")\n",
    "\n",
    "sectors=sectors.sort_values(\"COMPANY\", ascending=True)\n",
    "\n",
    "put_roi=pd.DataFrame(put_roi)\n",
    "put_roi.to_csv('temporary.csv')\n",
    "put_roi=pd.read_csv(\"/users/jorge/temporary.csv\")\n",
    "\n",
    "sectors[\"ROI\"]=put_roi[\"ROI\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE FINAL CIAS TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sectors.to_csv(\"finalcias.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD GENERAL & CLEAN zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totals=pd.read_csv(\"/users/jorge/sectorcall1114.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1517"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "put=totals\n",
    "put=put[put[\"LIQ\"]!=0]\n",
    "put.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EFFICIENCY MEASURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "n=put.shape[0]\n",
    "maxo=[]\n",
    "\n",
    "\n",
    "for i in range(0,n):\n",
    "    if put[\"TARGET\"].iloc[i]< (put[\"MAX\"].iloc[i])*(0.9):\n",
    "        maxo.append(1)\n",
    "    else:\n",
    "        maxo.append(0)\n",
    "      \n",
    "put[\"MAX90\"]=maxo\n",
    "ninety=put[\"MAX90\"].mean() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "maxo=[] \n",
    "for i in range(0,n):\n",
    "    if put[\"TARGET\"].iloc[i]< (put[\"MAX\"].iloc[i])*(0.91):\n",
    "        maxo.append(1)\n",
    "    else:\n",
    "        maxo.append(0)\n",
    "      \n",
    "put[\"MAX90\"]=maxo\n",
    "ninety1=put[\"MAX90\"].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "maxo=[]\n",
    "for i in range(0,n):\n",
    "    if put[\"TARGET\"].iloc[i]< (put[\"MAX\"].iloc[i])*(0.92):\n",
    "        maxo.append(1)\n",
    "    else:\n",
    "        maxo.append(0)\n",
    "      \n",
    "put[\"MAX90\"]=maxo\n",
    "ninety2=put[\"MAX90\"].mean()\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "maxo=[]\n",
    "for i in range(0,n):\n",
    "    if put[\"TARGET\"].iloc[i]< (put[\"MAX\"].iloc[i])*(0.93):\n",
    "        maxo.append(1)\n",
    "    else:\n",
    "        maxo.append(0)\n",
    "      \n",
    "put[\"MAX90\"]=maxo\n",
    "ninety3=put[\"MAX90\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "maxo=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    if put[\"TARGET\"].iloc[i]< (put[\"MAX\"].iloc[i])*(0.94):\n",
    "        maxo.append(1)\n",
    "    else:\n",
    "        maxo.append(0)\n",
    "put[\"MAX90\"]=maxo\n",
    "ninety4=put[\"MAX90\"].mean()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "maxo=[]\n",
    "for i in range(0,n):\n",
    "    if put[\"TARGET\"].iloc[i]< (put[\"MAX\"].iloc[i])*(0.95):\n",
    "        maxo.append(1)\n",
    "    else:\n",
    "        maxo.append(0)\n",
    "      \n",
    "put[\"MAX90\"]=maxo\n",
    "ninety5=put[\"MAX90\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "maxo=[]\n",
    "for i in range(0,n):\n",
    "    if put[\"TARGET\"].iloc[i]< (put[\"MAX\"].iloc[i])*(0.96):\n",
    "        maxo.append(1)\n",
    "    else:\n",
    "        maxo.append(0)\n",
    "      \n",
    "put[\"MAX90\"]=maxo\n",
    "ninety6=put[\"MAX90\"].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "maxo=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    if put[\"TARGET\"].iloc[i]< (put[\"MAX\"].iloc[i])*(0.97):\n",
    "        maxo.append(1)\n",
    "    else:\n",
    "        maxo.append(0)\n",
    "      \n",
    "put[\"MAX90\"]=maxo\n",
    "ninety7=put[\"MAX90\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "maxo=[]\n",
    "for i in range(0,n):\n",
    "    if put[\"TARGET\"].iloc[i]< (put[\"MAX\"].iloc[i])*(0.98):\n",
    "        maxo.append(1)\n",
    "    else:\n",
    "        maxo.append(0)\n",
    "      \n",
    "\n",
    "put[\"MAX90\"]=maxo\n",
    "ninety8=put[\"MAX90\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "maxo=[]\n",
    "for i in range(0,n):\n",
    "    if put[\"TARGET\"].iloc[i]< (put[\"MAX\"].iloc[i])*(0.99):\n",
    "        maxo.append(1)\n",
    "    else:\n",
    "        maxo.append(0)\n",
    "put[\"MAX90\"]=maxo\n",
    "ninety9=put[\"MAX90\"].mean()     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1001977587343441,\n",
       " 0.11865524060646011,\n",
       " 0.14172709294660515,\n",
       " 0.16941331575477916,\n",
       " 0.2023731048121292,\n",
       " 0.24719841793012526,\n",
       " 0.2992748846407383,\n",
       " 0.3553065260382334,\n",
       " 0.4218852999340804,\n",
       " 0.4990112063282795,\n",
       " 0.5926170072511536]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxo=[]\n",
    "\n",
    "for i in range(0,n):\n",
    "    if put[\"TARGET\"].iloc[i]< (put[\"MAX\"].iloc[i]):\n",
    "        maxo.append(1)\n",
    "    else:\n",
    "        maxo.append(0)\n",
    "      \n",
    "put[\"MAX90\"]=maxo\n",
    "hundred=put[\"MAX90\"].mean()\n",
    "frames=[ninety,ninety1,ninety2,ninety3, ninety4,ninety5,ninety6,ninety7,ninety8,ninety9, hundred]\n",
    "frames\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESCRIPTIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of options: 1517\n"
     ]
    }
   ],
   "source": [
    "print(\"number of options:\",put.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5926170072511536\n",
      "0.5561941331575492\n",
      "843.7465000000021\n",
      "0.6727393635875042\n",
      "1020.5456145622438\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(put[\"TRIGGER\"].mean())\n",
    "print(put[\"NET\"].mean())\n",
    "print(put[\"NET\"].sum())\n",
    "print(put[\"ROI\"].mean())\n",
    "print(put[\"ROI\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILTER BLACK SWANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2    0.329416\n",
       "0.4    0.688144\n",
       "0.6    1.321970\n",
       "0.8    2.653445\n",
       "Name: ROI, dtype: float64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winners=put[put[\"TRIGGER\"]==1]\n",
    "winners[\"ROI\"].quantile([0.2,0.4,0.6,0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blackswans=put[put[\"ROI\"]>2.65]\n",
    "not_blackswans=winners[winners[\"ROI\"]<=2.65]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FREQUENCIES OF SECTORS & COMPANIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    508\n",
       "2    350\n",
       "5    324\n",
       "3    211\n",
       "1     77\n",
       "4     47\n",
       "Name: SECTOR_CODE, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = pd.Categorical.from_array(put[\"SECTOR\"])\n",
    "col.codes\n",
    "put[\"SECTOR_CODE\"]=col.codes\n",
    "put[\"SECTOR_CODE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEF    281\n",
      "BBV    241\n",
      "SAN    218\n",
      "REP    136\n",
      "IBE     87\n",
      "ITX     71\n",
      "REE     48\n",
      "ANA     42\n",
      "ENA     42\n",
      "BME     36\n",
      "ABE     35\n",
      "FCC     31\n",
      "POP     23\n",
      "ELE     22\n",
      "IDR     22\n",
      "AMS     21\n",
      "ACS     20\n",
      "GAM     17\n",
      "OHL     16\n",
      "GAS     15\n",
      "SAB     14\n",
      "TRE     14\n",
      "ACX     11\n",
      "FER     10\n",
      "MTS      8\n",
      "SVO      7\n",
      "IAG      7\n",
      "CAB      7\n",
      "BKI      5\n",
      "VIS      4\n",
      "MAP      4\n",
      "ABB      1\n",
      "EBR      1\n",
      "Name: COMPANY, dtype: int64\n",
      "TEF    0.185234\n",
      "BBV    0.158866\n",
      "SAN    0.143705\n",
      "REP    0.089651\n",
      "IBE    0.057350\n",
      "ITX    0.046803\n",
      "REE    0.031641\n",
      "ANA    0.027686\n",
      "ENA    0.027686\n",
      "BME    0.023731\n",
      "ABE    0.023072\n",
      "FCC    0.020435\n",
      "POP    0.015162\n",
      "ELE    0.014502\n",
      "IDR    0.014502\n",
      "AMS    0.013843\n",
      "ACS    0.013184\n",
      "GAM    0.011206\n",
      "OHL    0.010547\n",
      "GAS    0.009888\n",
      "SAB    0.009229\n",
      "TRE    0.009229\n",
      "ACX    0.007251\n",
      "FER    0.006592\n",
      "MTS    0.005274\n",
      "SVO    0.004614\n",
      "IAG    0.004614\n",
      "CAB    0.004614\n",
      "BKI    0.003296\n",
      "VIS    0.002637\n",
      "MAP    0.002637\n",
      "ABB    0.000659\n",
      "EBR    0.000659\n",
      "Name: COMPANY, dtype: float64\n",
      "TEF    0.314917\n",
      "ITX    0.154696\n",
      "BME    0.110497\n",
      "AMS    0.077348\n",
      "ELE    0.049724\n",
      "SAN    0.049724\n",
      "IDR    0.038674\n",
      "ANA    0.033149\n",
      "FER    0.033149\n",
      "ACX    0.033149\n",
      "REE    0.027624\n",
      "REP    0.022099\n",
      "GAM    0.022099\n",
      "TRE    0.016575\n",
      "ACS    0.011050\n",
      "IAG    0.005525\n",
      "Name: COMPANY, dtype: float64\n",
      "TEF    0.252089\n",
      "SAN    0.162953\n",
      "BBV    0.150418\n",
      "REP    0.084958\n",
      "IBE    0.066852\n",
      "ITX    0.051532\n",
      "REE    0.037604\n",
      "ENA    0.032033\n",
      "ABE    0.032033\n",
      "ANA    0.019499\n",
      "ELE    0.015320\n",
      "BME    0.015320\n",
      "ACS    0.009749\n",
      "GAM    0.009749\n",
      "IDR    0.009749\n",
      "IAG    0.008357\n",
      "VIS    0.005571\n",
      "TRE    0.005571\n",
      "MAP    0.005571\n",
      "SVO    0.004178\n",
      "FER    0.004178\n",
      "ACX    0.004178\n",
      "POP    0.004178\n",
      "AMS    0.002786\n",
      "OHL    0.002786\n",
      "BKI    0.002786\n",
      "Name: COMPANY, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(put[\"COMPANY\"].value_counts())\n",
    "print(put[\"COMPANY\"].value_counts(normalize=True))\n",
    "print(blackswans[\"COMPANY\"].value_counts(normalize=True))\n",
    "print(not_blackswans[\"COMPANY\"].value_counts(normalize=True))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BANKS       508\n",
      "ENERGY      350\n",
      "TECH        324\n",
      "INDUSTRY    211\n",
      "CONSUMER     77\n",
      "SERVICES     47\n",
      "Name: SECTOR, dtype: int64\n",
      "BANKS       0.334871\n",
      "ENERGY      0.230719\n",
      "TECH        0.213579\n",
      "INDUSTRY    0.139090\n",
      "CONSUMER    0.050758\n",
      "SERVICES    0.030982\n",
      "Name: SECTOR, dtype: float64\n",
      "TECH        0.430939\n",
      "CONSUMER    0.154696\n",
      "INDUSTRY    0.149171\n",
      "SERVICES    0.116022\n",
      "ENERGY      0.099448\n",
      "BANKS       0.049724\n",
      "Name: SECTOR, dtype: float64\n",
      "BANKS       0.320334\n",
      "TECH        0.264624\n",
      "ENERGY      0.236769\n",
      "INDUSTRY    0.091922\n",
      "CONSUMER    0.057103\n",
      "SERVICES    0.029248\n",
      "Name: SECTOR, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(put[\"SECTOR\"].value_counts())\n",
    "print(put[\"SECTOR\"].value_counts(normalize=True))\n",
    "print(blackswans[\"SECTOR\"].value_counts(normalize=True))\n",
    "print(not_blackswans[\"SECTOR\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLACKSWANS DESCRIPTIVE COMPARED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blackswans[\"ROI\"].sum()\n",
    "\n",
    "blackswans[\"NET\"].sum()\n",
    "\n",
    "not_blackswans[\"NET\"].sum()\n",
    "not_blackswans[\"ROI\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORRELATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "correlations= put.corr()\n",
    "\n",
    "\n",
    "correlations=correlations[[\"NET\",\"ROI\", \"TRIGGER\",\"STD\", \"PREMIUM\"]]\n",
    "\n",
    "corrblack= blackswans.corr()\n",
    "\n",
    "\n",
    "corrblack=corrblack[[\"NET\",\"ROI\", \"STD\",\"PREMIUM\"]]\n",
    "\n",
    "corrnotblack= not_blackswans.corr()\n",
    "\n",
    "\n",
    "corrnotblack=corrnotblack[[\"NET\",\"ROI\", \"STD\",\"PREMIUM\"]]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCATTERPLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.scatter(put[\"DELTA\"], put[\"NET\"])\n",
    "plt.axis([-0.1,1.1,-1,1.5])\n",
    "plt.xlabel(\"DELTA\")\n",
    "plt.ylabel(\"NET\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.scatter(winners[\"VOLATILITY\"], winners[\"ROI\"])\n",
    "plt.axis([10,50,-0.1,20])\n",
    "plt.xlabel(\"VOLATILITY\")\n",
    "plt.ylabel(\"ROI\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.scatter(put[\"DELTA\"], put[\"PREMIUM\"])\n",
    "\n",
    "plt.xlabel(\"DELTA\")\n",
    "plt.ylabel(\"PREMIUM\")\n",
    "\n",
    "plt.axis([-0.1,1.1,-0.1,0.6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.scatter(winners[\"GAIN\"],winners[\"ROI\"])\n",
    "\n",
    "plt.xlabel(\"GAIN\")\n",
    "plt.ylabel(\"ROI\")\n",
    "\n",
    "plt.axis([-0.5,1, -0.1,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.scatter(winners[\"DAYS\"],winners[\"ROI\"])\n",
    "\n",
    "plt.xlabel(\"DAYS\")\n",
    "plt.ylabel(\"ROI\")\n",
    "plt.axis([0,700,-0.1,20])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HISTOGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.hist(put[\"NET\"],bins=40)\n",
    "plt.axis([-2, 6, 0, 600])\n",
    "plt.xlabel(\"NET\")\n",
    "plt.ylabel(\"COUNT\")\n",
    "plt.axvline(x=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.hist(winners[\"ROI\"],bins=40)\n",
    "plt.axis([-1, 10, 0, 250])\n",
    "plt.xlabel(\"ROI\")\n",
    "plt.ylabel(\"COUNT\")\n",
    "plt.axvline(x=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOXPLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "sns.boxplot(x=put[\"TRIGGER\"], y= put[\"DELTA\"], width=0.2,linewidth=1)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=put[\"TRIGGER\"], y= put[\"VOLATILITY\"],linewidth=1)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=put[\"TRIGGER\"], y= put[\"DAYS\"],linewidth=1)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=put[\"TRIGGER\"], y= put[\"STD\"],linewidth=1)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=put[\"TRIGGER\"], y= put[\"1ySTD\"],linewidth=1)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=put[\"TRIGGER\"], y= put[\"6mSTD\"],linewidth=1)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=put[\"TRIGGER\"], y= put[\"3mSTD\"],linewidth=1)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=put[\"TRIGGER\"], y= put[\"PREMIUM\"],linewidth=1)\n",
    "plt.ylim(0, 0.3)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=put[\"TRIGGER\"], y= put[\"GAIN\"],linewidth=1)\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=put[\"HIGH DELTA\"], y= put[\"NET\"],linewidth=1)\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=put[\"HIGH DELTA\"], y= put[\"ROI\"],linewidth=1)\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=put[\"HIGH VOL\"], y= put[\"NET\"],linewidth=1)\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=put[\"HIGH VOL\"], y= put[\"ROI\"],linewidth=1)\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=put[\"HIGH PREM\"], y= put[\"NET\"],linewidth=1)\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=put[\"HIGH PREM\"], y= put[\"ROI\"],linewidth=1)\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=put[\"DURATION\"], y= put[\"NET\"],linewidth=1)\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=put[\"DURATION\"], y= put[\"ROI\"],linewidth=1)\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=put[\"SECTOR_CODE\"], y= put[\"NET\"],linewidth=1)\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq4AAAHxCAYAAACszz65AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABsgeIKAAAAW/j/gVv1azvTfwwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118ce58d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=put[\"SECTOR_CODE\"], y= put[\"ROI\"],linewidth=1)\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "put_novdet=put\n",
    "put_novdet.dropna()\n",
    "put_novdet=put_novdet[['COMPANY', 'SECTOR', 'CODE', 'DATE', 'STRIKE', 'STRIKE_DATE',\n",
    "       'DAYS', 'LIQ', 'VOLUME', 'DELTA', 'VOLATILITY', 'MAX', 'TARGET',\n",
    "       'TRIGGER', 'NET', 'ROI', 'PREMIUM', 'GAIN', 'STD', '1ySTD', '6mSTD',\n",
    "       '3mSTD', 'HIGH DELTA', 'HIGH VOL', 'HIGH PREM', 'DURATION', 'SECTOR_CODE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "cols = put_novdet.columns\n",
    "train_cols = cols.drop([\"COMPANY\", \"CODE\", \"SECTOR\", \"DATE\", \"STRIKE\", \"STRIKE_DATE\", \"LIQ\",\"VOLUME\", \"TRIGGER\",\"GAIN\", \"STD\",\"MAX\", \"NET\", \"ROI\",\"SECTOR_CODE\" ])\n",
    "features = put_novdet[train_cols]\n",
    "target = put_novdet[\"TRIGGER\"]\n",
    "lr.fit(features, target)\n",
    "predictions = lr.predict(features)\n",
    "put_novdet[\"PREDICT\"]=predictions\n",
    "\n",
    "\n",
    "\n",
    "# False positives.\n",
    "fp_filter = put_novdet[(put_novdet[\"PREDICT\"] == 1) & (put_novdet[\"TRIGGER\"] == 0)]\n",
    "fp = len(fp_filter)\n",
    "\n",
    "# True positives.\n",
    "tp_filter = put_novdet[(put_novdet[\"PREDICT\"] == 1) & (put_novdet[\"TRIGGER\"] == 1)]\n",
    "tp = len(tp_filter)\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = put_novdet[(put_novdet[\"PREDICT\"] == 0) & (put_novdet[\"TRIGGER\"] == 1)]\n",
    "fn= len(fn_filter)\n",
    "# True negatives\n",
    "tn_filter = put_novdet[(put_novdet[\"PREDICT\"] == 0) & (put_novdet[\"TRIGGER\"] == 0)]\n",
    "tn= len(tn_filter)\n",
    "\n",
    "# Rates\n",
    "\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "ppv=tp/ (tp + fp)\n",
    "npv= tn/ (tn + fn)\n",
    "specificity= tn /(fp + tn)\n",
    "accuracy=(tp + tn) / put_novdet.shape[0]\n",
    "print(\"Sensitivity:\",sensitivity)\n",
    "print(\"False positive rate:\",fpr)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ppv:\", ppv)\n",
    "print(\"npv:\", npv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_predict, KFold\n",
    "lr = LogisticRegression()\n",
    "kf = KFold(features.shape[0], random_state=1)\n",
    "predictions = cross_val_predict(lr, features, target, cv=kf)\n",
    "predictions = pd.Series(predictions)\n",
    "put_novdet[\"PREDICT\"]=predictions\n",
    "\n",
    "# False positives.\n",
    "fp_filter = put_novdet[(put_novdet[\"PREDICT\"] == 1) & (put_novdet[\"TRIGGER\"] == 0)]\n",
    "fp = len(fp_filter)\n",
    "\n",
    "# True positives.\n",
    "tp_filter = put_novdet[(put_novdet[\"PREDICT\"] == 1) & (put_novdet[\"TRIGGER\"] == 1)]\n",
    "tp = len(tp_filter)\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = put_novdet[(put_novdet[\"PREDICT\"] == 0) & (put_novdet[\"TRIGGER\"] == 1)]\n",
    "fn= len(fn_filter)\n",
    "# True negatives\n",
    "tn_filter = put_novdet[(put_novdet[\"PREDICT\"] == 0) & (put_novdet[\"TRIGGER\"] == 0)]\n",
    "tn= len(tn_filter)\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "ppv=tp/ (tp + fp)\n",
    "npv= tn/ (tn + fn)\n",
    "specificity= tn /(fp + tn)\n",
    "accuracy=(tp + tn) / put_novdet.shape[0]\n",
    "print(sensitivity)\n",
    "print(fpr)\n",
    "print( specificity)\n",
    "print(accuracy)\n",
    "print( ppv)\n",
    "print( npv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "kf = KFold(features.shape[0], random_state=1)\n",
    "predictions = cross_val_predict(lr, features, target, cv=kf)\n",
    "predictions = pd.Series(predictions)\n",
    "put_novdet[\"PREDICT\"]=predictions\n",
    "\n",
    "# False positives.\n",
    "fp_filter = put_novdet[(put_novdet[\"PREDICT\"] == 1) & (put_novdet[\"TRIGGER\"] == 0)]\n",
    "fp = len(fp_filter)\n",
    "\n",
    "# True positives.\n",
    "tp_filter = put_novdet[(put_novdet[\"PREDICT\"] == 1) & (put_novdet[\"TRIGGER\"] == 1)]\n",
    "tp = len(tp_filter)\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = put_novdet[(put_novdet[\"PREDICT\"] == 0) & (put_novdet[\"TRIGGER\"] == 1)]\n",
    "fn= len(fn_filter)\n",
    "# True negatives\n",
    "tn_filter = put_novdet[(put_novdet[\"PREDICT\"] == 0) & (put_novdet[\"TRIGGER\"] == 0)]\n",
    "tn= len(tn_filter)\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "ppv=tp/ (tp + fp)\n",
    "npv= tn/ (tn + fn)\n",
    "specificity= tn /(fp + tn)\n",
    "accuracy=(tp + tn) / put_novdet.shape[0]\n",
    "print(sensitivity)\n",
    "print(fpr)\n",
    "print( specificity)\n",
    "print(accuracy)\n",
    "print( ppv)\n",
    "print( npv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "penalty = {\n",
    "    0: 4,\n",
    "    1: 1\n",
    "}\n",
    "\n",
    "lr = LogisticRegression(class_weight=penalty)\n",
    "kf = KFold(features.shape[0], random_state=1)\n",
    "predictions = cross_val_predict(lr, features, target, cv=kf)\n",
    "predictions = pd.Series(predictions)\n",
    "put_novdet[\"PREDICT\"]=predictions\n",
    "\n",
    "# False positives.\n",
    "fp_filter = put_novdet[(put_novdet[\"PREDICT\"] == 1) & (put_novdet[\"TRIGGER\"] == 0)]\n",
    "fp = len(fp_filter)\n",
    "\n",
    "# True positives.\n",
    "tp_filter = put_novdet[(put_novdet[\"PREDICT\"] == 1) & (put_novdet[\"TRIGGER\"] == 1)]\n",
    "tp = len(tp_filter)\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = put_novdet[(put_novdet[\"PREDICT\"] == 0) & (put_novdet[\"TRIGGER\"] == 1)]\n",
    "fn= len(fn_filter)\n",
    "# True negatives\n",
    "tn_filter = put_novdet[(put_novdet[\"PREDICT\"] == 0) & (put_novdet[\"TRIGGER\"] == 0)]\n",
    "tn= len(tn_filter)\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "ppv=tp/ (tp + fp)\n",
    "npv= tn/ (tn + fn)\n",
    "specificity= tn /(fp + tn)\n",
    "accuracy=(tp + tn) / put_novdet.shape[0]\n",
    "print(sensitivity)\n",
    "print(fpr)\n",
    "print( specificity)\n",
    "print(accuracy)\n",
    "print( ppv)\n",
    "print( npv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\", random_state=1)\n",
    "kf = KFold(features.shape[0], random_state=1)\n",
    "predictions = cross_val_predict(rf, features, target, cv=kf)\n",
    "predictions = pd.Series(predictions)\n",
    "put_novdet[\"PREDICT\"]=predictions\n",
    "\n",
    "# False positives.\n",
    "fp_filter = put_novdet[(put_novdet[\"PREDICT\"] == 1) & (put_novdet[\"TRIGGER\"] == 0)]\n",
    "fp = len(fp_filter)\n",
    "\n",
    "# True positives.\n",
    "tp_filter = put_novdet[(put_novdet[\"PREDICT\"] == 1) & (put_novdet[\"TRIGGER\"] == 1)]\n",
    "tp = len(tp_filter)\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = put_novdet[(put_novdet[\"PREDICT\"] == 0) & (put_novdet[\"TRIGGER\"] == 1)]\n",
    "fn= len(fn_filter)\n",
    "# True negatives\n",
    "tn_filter = put_novdet[(put_novdet[\"PREDICT\"] == 0) & (put_novdet[\"TRIGGER\"] == 0)]\n",
    "tn= len(tn_filter)\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "ppv=tp/ (tp + fp)\n",
    "npv= tn/ (tn + fn)\n",
    "specificity= tn /(fp + tn)\n",
    "accuracy=(tp + tn) / put_novdet.shape[0]\n",
    "print(sensitivity)\n",
    "print(fpr)\n",
    "print( specificity)\n",
    "print(accuracy)\n",
    "print( ppv)\n",
    "print( npv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN & TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from numpy.random import permutation\n",
    "random_indices=permutation(put_novdet.index)\n",
    "test_cutoff=math.floor(len(put_novdet)/3)\n",
    "test=put_novdet.loc[random_indices[1:test_cutoff]]\n",
    "train=put_novdet.loc[random_indices[test_cutoff:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression()\n",
    "model.fit(train[[\"VOLATILITY\"]], train[\"TRIGGER\"])\n",
    "labels=model.predict(test[[\"VOLATILITY\"]])\n",
    "test[\"predicted_TRIGGER\"]=labels\n",
    "matches=test[\"predicted_TRIGGER\"]==test[\"TRIGGER\"]\n",
    "correct_predictions=test[matches]\n",
    "accuracy=len(correct_predictions)/len(test)\n",
    "true_positive_filter = (test[\"predicted_TRIGGER\"] == 1) & (test[\"TRIGGER\"] == 1)\n",
    "true_positives = len(test[true_positive_filter])\n",
    "false_negative_filter = (test[\"predicted_TRIGGER\"] == 0) & (test[\"TRIGGER\"] == 1)\n",
    "false_negatives = len(test[false_negative_filter])\n",
    "true_negative_filter = (test[\"predicted_TRIGGER\"] == 0) & (test[\"TRIGGER\"] == 0)\n",
    "true_negatives = len(test[true_negative_filter])\n",
    "false_positive_filter = (test[\"predicted_TRIGGER\"] == 1) & (test[\"TRIGGER\"] == 0)\n",
    "false_positives = len(test[false_positive_filter])\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "specificity= true_negatives / (false_positives + true_negatives) \n",
    "\n",
    "accuracy=(true_positives + true_negatives) / test.shape[0]\n",
    "\n",
    "\n",
    "fpr = false_positives / (false_positives + true_negatives)\n",
    "ppv=true_positives/ (true_positives + false_positives)\n",
    "npv= true_negatives/ (true_negatives + false_negatives)\n",
    "\n",
    "print(sensitivity)\n",
    "print(fpr)\n",
    "print( specificity)\n",
    "print(accuracy)\n",
    "print( ppv)\n",
    "print( npv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression()\n",
    "model.fit(train[[\"DELTA\"]], train[\"TRIGGER\"])\n",
    "labels=model.predict(test[[\"DELTA\"]])\n",
    "test[\"predicted_TRIGGER\"]=labels\n",
    "matches=test[\"predicted_TRIGGER\"]==test[\"TRIGGER\"]\n",
    "correct_predictions=test[matches]\n",
    "accuracy=len(correct_predictions)/len(test)\n",
    "true_positive_filter = (test[\"predicted_TRIGGER\"] == 1) & (test[\"TRIGGER\"] == 1)\n",
    "true_positives = len(test[true_positive_filter])\n",
    "false_negative_filter = (test[\"predicted_TRIGGER\"] == 0) & (test[\"TRIGGER\"] == 1)\n",
    "false_negatives = len(test[false_negative_filter])\n",
    "true_negative_filter = (test[\"predicted_TRIGGER\"] == 0) & (test[\"TRIGGER\"] == 0)\n",
    "true_negatives = len(test[true_negative_filter])\n",
    "false_positive_filter = (test[\"predicted_TRIGGER\"] == 1) & (test[\"TRIGGER\"] == 0)\n",
    "false_positives = len(test[false_positive_filter])\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "specificity= true_negatives / (false_positives + true_negatives) \n",
    "\n",
    "accuracy=(true_positives + true_negatives) / test.shape[0]\n",
    "\n",
    "\n",
    "fpr = false_positives / (false_positives + true_negatives)\n",
    "ppv=true_positives/ (true_positives + false_positives)\n",
    "npv= true_negatives/ (true_negatives + false_negatives)\n",
    "\n",
    "print(sensitivity)\n",
    "print(fpr)\n",
    "print( specificity)\n",
    "print(accuracy)\n",
    "print( ppv)\n",
    "print( npv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression()\n",
    "model.fit(train[[\"PREMIUM\"]], train[\"TRIGGER\"])\n",
    "labels=model.predict(test[[\"PREMIUM\"]])\n",
    "test[\"predicted_TRIGGER\"]=labels\n",
    "matches=test[\"predicted_TRIGGER\"]==test[\"TRIGGER\"]\n",
    "correct_predictions=test[matches]\n",
    "accuracy=len(correct_predictions)/len(test)\n",
    "true_positive_filter = (test[\"predicted_TRIGGER\"] == 1) & (test[\"TRIGGER\"] == 1)\n",
    "true_positives = len(test[true_positive_filter])\n",
    "false_negative_filter = (test[\"predicted_TRIGGER\"] == 0) & (test[\"TRIGGER\"] == 1)\n",
    "false_negatives = len(test[false_negative_filter])\n",
    "true_negative_filter = (test[\"predicted_TRIGGER\"] == 0) & (test[\"TRIGGER\"] == 0)\n",
    "true_negatives = len(test[true_negative_filter])\n",
    "false_positive_filter = (test[\"predicted_TRIGGER\"] == 1) & (test[\"TRIGGER\"] == 0)\n",
    "false_positives = len(test[false_positive_filter])\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "specificity= true_negatives / (false_positives + true_negatives) \n",
    "\n",
    "accuracy=(true_positives + true_negatives) / test.shape[0]\n",
    "\n",
    "\n",
    "fpr = false_positives / (false_positives + true_negatives)\n",
    "ppv=true_positives/ (true_positives + false_positives)\n",
    "\n",
    "\n",
    "print(sensitivity)\n",
    "print(fpr)\n",
    "print( specificity)\n",
    "print(accuracy)\n",
    "print( ppv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "probabilities = model.predict_proba(test[[\"VOLATILITY\"]])\n",
    "\n",
    "# Means we can just use roc_auc_curve() instead of metrics.roc_auc_curve()\n",
    "auc_score = roc_auc_score(test[\"TRIGGER\"], probabilities[:,1])\n",
    "print(auc_score)\n",
    "probabilities = model.predict_proba(test[[\"DELTA\"]])\n",
    "\n",
    "# Means we can just use roc_auc_curve() instead of metrics.roc_auc_curve()\n",
    "auc_score = roc_auc_score(test[\"TRIGGER\"], probabilities[:,1])\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "admissions = put\n",
    "admissions[\"actual_label\"] = admissions[\"TRIGGER\"]\n",
    "cols = admissions.columns\n",
    "train_cols = cols.drop([\"COMPANY\",\"SECTOR\", \"CODE\", \"DATE\", \"STRIKE\", \"LIQ\",\"VOLUME\", \"TRIGGER\", \"STRIKE_DATE\", \"GAIN\", \"STD\",\"MAX\", \"NET\", \"ROI\"])\n",
    "admissions = admissions[train_cols]\n",
    "\n",
    "\n",
    "kf=KFold(len(admissions), 5, shuffle=True, random_state=8)\n",
    "lr=LogisticRegression()\n",
    "\n",
    "\n",
    "accuracies=cross_val_score(lr, admissions[[\"VOLATILITY\"]],admissions[\"actual_label\"],scoring=\"accuracy\",cv=kf)\n",
    "average_accuracies=sum(accuracies)/len(accuracies)\n",
    "\n",
    "print(average_accuracies)\n",
    "accuracies=cross_val_score(lr, admissions[[\"HIGH DELTA\"]],admissions[\"actual_label\"],scoring=\"accuracy\",cv=kf)\n",
    "average_accuracies=sum(accuracies)/len(accuracies)\n",
    "\n",
    "print(average_accuracies)\n",
    "accuracies=cross_val_score(lr, admissions[[\"DELTA\"]],admissions[\"actual_label\"],scoring=\"accuracy\",cv=kf)\n",
    "average_accuracies=sum(accuracies)/len(accuracies)\n",
    "\n",
    "print(average_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression()\n",
    "model.fit(train[[\"DELTA\", \"VOLATILITY\", \"PREMIUM\"]], train[\"TRIGGER\"])\n",
    "labels=model.predict(test[[\"DELTA\", \"VOLATILITY\", \"PREMIUM\"]])\n",
    "test[\"predicted_TRIGGER\"]=labels\n",
    "matches=test[\"predicted_TRIGGER\"]==test[\"TRIGGER\"]\n",
    "correct_predictions=test[matches]\n",
    "accuracy=len(correct_predictions)/len(test)\n",
    "true_positive_filter = (test[\"predicted_TRIGGER\"] == 1) & (test[\"TRIGGER\"] == 1)\n",
    "true_positives = len(test[true_positive_filter])\n",
    "false_negative_filter = (test[\"predicted_TRIGGER\"] == 0) & (test[\"TRIGGER\"] == 1)\n",
    "false_negatives = len(test[false_negative_filter])\n",
    "true_negative_filter = (test[\"predicted_TRIGGER\"] == 0) & (test[\"TRIGGER\"] == 0)\n",
    "true_negatives = len(test[true_negative_filter])\n",
    "false_positive_filter = (test[\"predicted_TRIGGER\"] == 1) & (test[\"TRIGGER\"] == 0)\n",
    "false_positives = len(test[false_positive_filter])\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "specificity= true_negatives / (false_positives + true_negatives) \n",
    "\n",
    "accuracy=(true_positives + true_negatives) / test.shape[0]\n",
    "\n",
    "\n",
    "fpr = false_positives / (false_positives + true_negatives)\n",
    "ppv=true_positives/ (true_positives + false_positives)\n",
    "npv= true_negatives/ (true_negatives + false_negatives)\n",
    "\n",
    "print(sensitivity)\n",
    "print(fpr)\n",
    "print( specificity)\n",
    "print(accuracy)\n",
    "print( ppv)\n",
    "print(npv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression()\n",
    "model.fit(train[[\"STD\", \"GAIN\"]], train[\"TRIGGER\"])\n",
    "labels=model.predict(test[[\"STD\", \"GAIN\"]])\n",
    "test[\"predicted_TRIGGER\"]=labels\n",
    "matches=test[\"predicted_TRIGGER\"]==test[\"TRIGGER\"]\n",
    "correct_predictions=test[matches]\n",
    "accuracy=len(correct_predictions)/len(test)\n",
    "true_positive_filter = (test[\"predicted_TRIGGER\"] == 1) & (test[\"TRIGGER\"] == 1)\n",
    "true_positives = len(test[true_positive_filter])\n",
    "false_negative_filter = (test[\"predicted_TRIGGER\"] == 0) & (test[\"TRIGGER\"] == 1)\n",
    "false_negatives = len(test[false_negative_filter])\n",
    "true_negative_filter = (test[\"predicted_TRIGGER\"] == 0) & (test[\"TRIGGER\"] == 0)\n",
    "true_negatives = len(test[true_negative_filter])\n",
    "false_positive_filter = (test[\"predicted_TRIGGER\"] == 1) & (test[\"TRIGGER\"] == 0)\n",
    "false_positives = len(test[false_positive_filter])\n",
    "sensitivity = true_positives / (true_positives + false_negatives)\n",
    "specificity= true_negatives / (false_positives + true_negatives) \n",
    "\n",
    "accuracy=(true_positives + true_negatives) / test.shape[0]\n",
    "\n",
    "\n",
    "fpr = false_positives / (false_positives + true_negatives)\n",
    "ppv=true_positives/ (true_positives + false_positives)\n",
    "npv= true_negatives/ (true_negatives + false_negatives)\n",
    "\n",
    "print(sensitivity)\n",
    "print(fpr)\n",
    "print( specificity)\n",
    "print(accuracy)\n",
    "print( ppv)\n",
    "print(npv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = put_novdet[[\"DELTA\", \"VOLATILITY\"]]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\", random_state=1)\n",
    "kf = KFold(features.shape[0], random_state=1)\n",
    "predictions = cross_val_predict(rf, features, target, cv=kf)\n",
    "predictions = pd.Series(predictions)\n",
    "put_novdet[\"PREDICT\"]=predictions\n",
    "\n",
    "# False positives.\n",
    "fp_filter = put_novdet[(put_novdet[\"PREDICT\"] == 1) & (put_novdet[\"TRIGGER\"] == 0)]\n",
    "fp = len(fp_filter)\n",
    "\n",
    "# True positives.\n",
    "tp_filter = put_novdet[(put_novdet[\"PREDICT\"] == 1) & (put_novdet[\"TRIGGER\"] == 1)]\n",
    "tp = len(tp_filter)\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = put_novdet[(put_novdet[\"PREDICT\"] == 0) & (put_novdet[\"TRIGGER\"] == 1)]\n",
    "fn= len(fn_filter)\n",
    "# True negatives\n",
    "tn_filter = put_novdet[(put_novdet[\"PREDICT\"] == 0) & (put_novdet[\"TRIGGER\"] == 0)]\n",
    "tn= len(tn_filter)\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "ppv=tp/ (tp + fp)\n",
    "npv= tn/ (tn + fn)\n",
    "specificity= tn /(fp + tn)\n",
    "accuracy=(tp + tn) / put_novdet.shape[0]\n",
    "print(sensitivity)\n",
    "print(fpr)\n",
    "print( specificity)\n",
    "print(accuracy)\n",
    "print( ppv)\n",
    "print(npv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "admissions = put\n",
    "\n",
    "col = admissions.columns\n",
    "train_cols = col.drop([\"COMPANY\", \"SECTOR\",\"CODE\", \"DATE\", \"STRIKE\", \"LIQ\",\"VOLUME\", \"TRIGGER\", \"STRIKE_DATE\", \"GAIN\", \"STD\",\"MAX\", \"ROI\"])\n",
    "admissions = admissions[train_cols]\n",
    "def train_and_test(cols):\n",
    "    # Split into features & target.\n",
    "    features = admissions[cols]\n",
    "    target = admissions[\"NET\"]\n",
    "    # Fit model.\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(features, target)\n",
    "    # Make predictions on training set.\n",
    "    predictions = lr.predict(features)\n",
    "    # Compute MSE and Variance.\n",
    "    mse = mean_squared_error(admissions[\"NET\"], predictions)\n",
    "    variance = np.var(predictions)\n",
    "    return(mse, variance)\n",
    "    \n",
    "del_mse, del_var = train_and_test([\"DELTA\"])\n",
    "\n",
    "vol_mse, vol_var = train_and_test([\"VOLATILITY\"])\n",
    "pre_mse, pre_var = train_and_test([\"PREMIUM\"])\n",
    "day_mse, day_var = train_and_test([\"DAYS\"])\n",
    "yst_mse, yst_var = train_and_test([\"1ySTD\"])\n",
    "print(del_mse, del_var)\n",
    "print(vol_mse, vol_var)\n",
    "print(pre_mse,pre_var)\n",
    "print(day_mse, day_var)\n",
    "print(yst_mse, yst_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "admissions = put\n",
    "\n",
    "col = admissions.columns\n",
    "def train_and_cross_val(cols):\n",
    "    features = admissions[cols]\n",
    "    target = admissions[\"NET\"]\n",
    "    \n",
    "    variance_values = []\n",
    "    mse_values = []\n",
    "  \n",
    "\n",
    "    \n",
    "    # KFold instance.\n",
    "    kf = KFold(n=len(admissions), n_folds=10, shuffle=True, random_state=3)\n",
    "    \n",
    "    # Iterate through over each fold.\n",
    "    for train_index, test_index in kf:\n",
    "        # Training and test sets.\n",
    "        X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "        y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "        \n",
    "        # Fit the model and make predictions.\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        predictions = lr.predict(X_test)\n",
    "        \n",
    "        # Calculate mse and variance values for this fold.\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        var = np.var(predictions)\n",
    "\n",
    "        # Append to arrays to do calculate overall average mse and variance values.\n",
    "        variance_values.append(var)\n",
    "        mse_values.append(mse)\n",
    "        \n",
    "   \n",
    "    # Compute average mse and variance values.\n",
    "    avg_mse = np.mean(mse_values)\n",
    "    avg_var = np.mean(variance_values)\n",
    "    return(avg_mse, avg_var)\n",
    "        \n",
    "two_mse, two_var = train_and_cross_val([\"VOLATILITY\"])\n",
    "\n",
    "print(two_mse)\n",
    "print(two_var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENTROPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def calc_entropy(column):\n",
    "    \"\"\"\n",
    "    Calculate entropy given a pandas Series, list, or numpy array.\n",
    "    \"\"\"\n",
    "    # Compute the counts of each unique value in the column.\n",
    "    counts = numpy.bincount(column)\n",
    "    # Divide by the total column length to get a probability.\n",
    "    probabilities = counts / len(column)\n",
    "    \n",
    "    # Initialize the entropy to 0.\n",
    "    entropy = 0\n",
    "    # Loop through the probabilities, and add each one to the total entropy.\n",
    "    for prob in probabilities:\n",
    "        if prob > 0:\n",
    "            entropy += prob * math.log(prob, 2)\n",
    "    \n",
    "    return -entropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "admissions=put\n",
    "income_entropy = calc_entropy(put[\"HIGH DELTA\"])\n",
    "median_age = put[\"ROI\"].median()\n",
    "\n",
    "left_split = put[put[\"ROI\"] <= median_age]\n",
    "right_split = put[put[\"ROI\"] > median_age]\n",
    "\n",
    "age_information_gain = income_entropy - ((left_split.shape[0] / put.shape[0]) * calc_entropy(left_split[\"HIGH DELTA\"]) + ((right_split.shape[0] / put.shape[0]) * calc_entropy(right_split[\"HIGH DELTA\"])))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_information_gain(data, split_name, target_name):\n",
    "    \"\"\"\n",
    "    Calculate information gain given a dataset, column to split on, and target.\n",
    "    \"\"\"\n",
    "    # Calculate original entropy.\n",
    "    original_entropy = calc_entropy(data[target_name])\n",
    "    \n",
    "    # Find the median of the column we're splitting.\n",
    "    column = data[split_name]\n",
    "    median = column.median()\n",
    "    \n",
    "    # Make two subsets of the data based on the median.\n",
    "    left_split = data[column <= median]\n",
    "    right_split = data[column > median]\n",
    "    \n",
    "    # Loop through the splits, and calculate the subset entropy.\n",
    "    to_subtract = 0\n",
    "    for subset in [left_split, right_split]:\n",
    "        prob = (subset.shape[0] / data.shape[0]) \n",
    "        to_subtract += prob * calc_entropy(subset[target_name])\n",
    "    \n",
    "    # Return information gain.\n",
    "    return original_entropy - to_subtract\n",
    "\n",
    "# Verify that our answer is the same as in the last screen.\n",
    "print(calc_information_gain(put, \"VOLATILITY\", \"TRIGGER\"))\n",
    "print(calc_information_gain(put, \"DELTA\", \"TRIGGER\"))\n",
    "print(calc_information_gain(put, \"PREMIUM\", \"TRIGGER\"))\n",
    "print(calc_information_gain(put, \"NET\", \"HIGH VOL\"))\n",
    "print(calc_information_gain(put, \"NET\", \"HIGH DELTA\"))\n",
    "print(calc_information_gain(put, \"NET\", \"HIGH PREM\"))\n",
    "print(calc_information_gain(put, \"NET\", \"DURATION\"))\n",
    "print(calc_information_gain(put, \"NET\", \"SECTOR_CODE\"))\n",
    "print(calc_information_gain(put, \"ROI\", \"HIGH VOL\"))\n",
    "print(calc_information_gain(put, \"ROI\", \"HIGH DELTA\"))\n",
    "print(calc_information_gain(put, \"ROI\", \"HIGH PREM\"))\n",
    "print(calc_information_gain(put, \"ROI\", \"DURATION\"))\n",
    "print(calc_information_gain(put, \"ROI\", \"SECTOR_CODE\"))\n",
    "print(calc_information_gain(put, \"DAYS\", \"TRIGGER\"))\n",
    "print(calc_information_gain(put, \"VOLUME\", \"TRIGGER\"))\n",
    "print(calc_information_gain(put, \"1ySTD\", \"TRIGGER\"))\n",
    "print(calc_information_gain(put, \"GAIN\", \"TRIGGER\"))\n",
    "print(calc_information_gain(put, \"STD\", \"TRIGGER\"))\n",
    "print(calc_information_gain(put, \"3mSTD\", \"TRIGGER\"))\n",
    "print(calc_information_gain(put, \"6mSTD\", \"TRIGGER\"))\n",
    "print(calc_information_gain(put, \"SECTOR_CODE\", \"TRIGGER\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "prem=[]\n",
    "\n",
    "\n",
    "n=put.shape[0]\n",
    "for i in range(0,n) :\n",
    "    if put[\"NET\"].iloc[i]<=(0):\n",
    "        prem.append(1)\n",
    "    elif (put[\"NET\"].iloc[i]>(0)) & (put[\"NET\"].iloc[i]<(0.6)):\n",
    "        prem.append(2)\n",
    "    elif (put[\"NET\"].iloc[i]>=(0.6)):\n",
    "        prem.append(3)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "put[\"NETcat\"]=prem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(calc_information_gain(put, \"VOLATILITY\", \"NETcat\"))\n",
    "print(calc_information_gain(put, \"DELTA\", \"NETcat\"))\n",
    "print(calc_information_gain(put, \"PREMIUM\", \"NETcat\"))\n",
    "print(calc_information_gain(put, \"DAYS\", \"NETcat\"))\n",
    "print(calc_information_gain(put, \"VOLUME\", \"NETcat\"))\n",
    "print(calc_information_gain(put, \"1ySTD\", \"NETcat\"))\n",
    "print(calc_information_gain(put, \"GAIN\", \"NETcat\"))\n",
    "print(calc_information_gain(put, \"STD\", \"NETcat\"))\n",
    "print(calc_information_gain(put, \"3mSTD\", \"NETcat\"))\n",
    "print(calc_information_gain(put, \"6mSTD\", \"NETcat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prem=[]\n",
    "\n",
    "\n",
    "n=winners.shape[0]\n",
    "for i in range(0,n) :\n",
    "    if winners[\"ROI\"].iloc[i]<(0.5):\n",
    "        prem.append(1)\n",
    "    elif (winners[\"ROI\"].iloc[i]>=(0.5)) & (winners[\"ROI\"].iloc[i]<(2)):\n",
    "        prem.append(2)\n",
    "    elif (winners[\"ROI\"].iloc[i]>=(2)) :\n",
    "        prem.append(3)\n",
    "   \n",
    "\n",
    "\n",
    "winners[\"ROIcat\"]=prem\n",
    "print(calc_information_gain(winners, \"VOLATILITY\", \"ROIcat\"))\n",
    "print(calc_information_gain(winners, \"DELTA\", \"ROIcat\"))\n",
    "print(calc_information_gain(winners, \"PREMIUM\", \"ROIcat\"))\n",
    "print(calc_information_gain(winners, \"DAYS\", \"ROIcat\"))\n",
    "print(calc_information_gain(winners, \"VOLUME\", \"ROIcat\"))\n",
    "print(calc_information_gain(winners, \"1ySTD\", \"ROIcat\"))\n",
    "print(calc_information_gain(winners, \"GAIN\", \"ROIcat\"))\n",
    "print(calc_information_gain(winners, \"STD\", \"ROIcat\"))\n",
    "print(calc_information_gain(winners, \"3mSTD\", \"ROIcat\"))\n",
    "print(calc_information_gain(winners, \"6mSTD\", \"ROIcat\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALGORITMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "puto=put[[\"CODE\", \"COMPANY\", \"SECTOR_CODE\", \"DAYS\", \"DELTA\", \"VOLATILITY\", \"PREMIUM\", \"1ySTD\",\"DURATION\", \"HIGH PREM\",\"HIGH DELTA\", \"HIGH VOL\", \"TRIGGER\", \"NET\", \"ROI\", \"NETcat\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "puto[\"DELTAnorm\"]=(puto[\"DELTA\"]-puto[\"DELTA\"].mean()) /puto[\"DELTA\"].mean()\n",
    "puto[\"DAYSnorm\"]=(puto[\"DAYS\"]-puto[\"DAYS\"].mean()) /puto[\"DAYS\"].mean()\n",
    "puto[\"VOLATnorm\"]=(puto[\"VOLATILITY\"]-puto[\"VOLATILITY\"].mean()) /puto[\"VOLATILITY\"].mean()\n",
    "puto[\"PREMIUMnorm\"]=(puto[\"PREMIUM\"]-puto[\"PREMIUM\"].mean()) /puto[\"PREMIUM\"].mean()\n",
    "puto[\"1ySTDnorm\"]=(puto[\"1ySTD\"]-puto[\"1ySTD\"].mean()) /puto[\"1ySTD\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "prem=[]\n",
    "\n",
    "\n",
    "n=puto.shape[0]\n",
    "for i in range(0,n) :\n",
    "    if puto[\"ROI\"].iloc[i]<(0):\n",
    "        prem.append(1)\n",
    "    elif (puto[\"ROI\"].iloc[i]>=(0)) & (puto[\"ROI\"].iloc[i]<(1)):\n",
    "        prem.append(2)\n",
    "    elif (puto[\"ROI\"].iloc[i]>=(1)) :\n",
    "        prem.append(3)\n",
    "   \n",
    "\n",
    "\n",
    "puto[\"ROIcat\"]=prem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "money=(puto[\"DELTAnorm\"]*2)+ (puto[\"DELTA_net\"]*2) + (puto[\"VOL_net\"]*2)+ (puto[\"PREMIUMnorm\"]*3) + (puto[\"DAYSnorm\"]*3) + (puto[\"1ySTDnorm\"]*2) + (puto[\"VOLATnorm\"]*(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "money.quantile([0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prene=[]\n",
    "for i in money:\n",
    "    if i<=(5.911):\n",
    "        prene.append(0)\n",
    "    \n",
    "    else:\n",
    "        prene.append(1)\n",
    "puto[\"PRENET\"]=prene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp_filter = put_novdet[(puto[\"PRENET\"] == 1) & (puto[\"NETcat\"] != 3)]\n",
    "fp = len(fp_filter)\n",
    "\n",
    "# True positives.\n",
    "tp_filter = put_novdet[(puto[\"PRENET\"] == 1) & (puto[\"NETcat\"] == 3)]\n",
    "tp = len(tp_filter)\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = put_novdet[(puto[\"PRENET\"] ==0 ) & (puto[\"NETcat\"] == 3)]\n",
    "fn= len(fn_filter)\n",
    "# True negatives\n",
    "tn_filter = put_novdet[(puto[\"PRENET\"]== 0) & (puto[\"NETcat\"] != 3)]\n",
    "tn= len(tn_filter)\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "ppv=tp/ (tp + fp)\n",
    "npv= tn/ (tn + fn)\n",
    "specificity= tn /(fp + tn)\n",
    "accuracy=(tp + tn) / puto.shape[0]\n",
    "print(sensitivity)\n",
    "print(fpr)\n",
    "print( specificity)\n",
    "print(accuracy)\n",
    "print( ppv)\n",
    "print( npv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "safe=(puto[\"DELTAnorm\"]*5) + (puto[\"PREMIUMnorm\"]*3) + (puto[\"DAYSnorm\"]*2) + (puto[\"1ySTDnorm\"]*0) + (puto[\"VOLATnorm\"]*(-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "safe.quantile([0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prene=[]\n",
    "for i in safe:\n",
    "    if i<=(1.58):\n",
    "        prene.append(0)\n",
    "   \n",
    "    else:\n",
    "        prene.append(1)\n",
    "puto[\"PRETRIGGER\"]=prene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp_filter = put_novdet[(puto[\"PRETRIGGER\"] == 1) & (puto[\"TRIGGER\"] == 0)]\n",
    "fp = len(fp_filter)\n",
    "\n",
    "# True positives.\n",
    "tp_filter = put_novdet[(puto[\"PRETRIGGER\"] == 1) & (puto[\"TRIGGER\"] == 1)]\n",
    "tp = len(tp_filter)\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = put_novdet[(puto[\"PRETRIGGER\"] == 0) & (puto[\"TRIGGER\"] == 1)]\n",
    "fn= len(fn_filter)\n",
    "# True negatives\n",
    "tn_filter = put_novdet[(puto[\"PRETRIGGER\"]== 0) & (puto[\"TRIGGER\"] == 0)]\n",
    "tn= len(tn_filter)\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "ppv=tp/ (tp + fp)\n",
    "npv= tn/ (tn + fn)\n",
    "specificity= tn /(fp + tn)\n",
    "accuracy=(tp + tn) / puto.shape[0]\n",
    "print(sensitivity)\n",
    "print(fpr)\n",
    "print( specificity)\n",
    "print(accuracy)\n",
    "print( ppv)\n",
    "print( npv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preroi=(puto[\"DELTAnorm\"]*(-3)) + (puto[\"PREMIUMnorm\"]*(-3)) + (puto[\"DAYSnorm\"]*(-1)) + (puto[\"1ySTDnorm\"]*(-1)) + (puto[\"VOLATnorm\"]*(-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preroi.quantile([0.4,0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prene=[]\n",
    "for i in preroi:\n",
    "    if i<=(5.21):\n",
    "        prene.append(0)\n",
    "    \n",
    "    else:\n",
    "        prene.append(1)\n",
    "puto[\"PREROI\"]=prene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp_filter = puto[(puto[\"PREROI\"] == 1) & (puto[\"ROIcat\"] != 3)]\n",
    "fp = len(fp_filter)\n",
    "\n",
    "# True positives.\n",
    "tp_filter = puto[(puto[\"PREROI\"] == 1) & (puto[\"ROIcat\"] == 3)]\n",
    "tp = len(tp_filter)\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = puto[(puto[\"PREROI\"] == 0) & (puto[\"ROIcat\"] == 3)]\n",
    "fn= len(fn_filter)\n",
    "# True negatives\n",
    "tn_filter = puto[(puto[\"PREROI\"]== 0) & (puto[\"ROIcat\"] != 3)]\n",
    "tn= len(tn_filter)\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "ppv=tp/ (tp + fp)\n",
    "npv= tn/ (tn + fn)\n",
    "specificity= tn /(fp + tn)\n",
    "accuracy=(tp + tn) / puto.shape[0]\n",
    "print(sensitivity)\n",
    "print(fpr)\n",
    "print( specificity)\n",
    "print(accuracy)\n",
    "print( ppv)\n",
    "print( npv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=puto.shape[0]\n",
    "pros=[]\n",
    "for i in range(0,n):\n",
    "    if (puto[\"HIGH DELTA\"].iloc[i]==2) | puto[\"HIGH DELTA\"].iloc[i]==3 :\n",
    "        pros.append(1)\n",
    "    elif (puto[\"HIGH DELTA\"].iloc[i]==1) | puto[\"HIGH DELTA\"].iloc[i]==5:\n",
    "        pros.append(-1)\n",
    "    else:\n",
    "        pros.append(0)\n",
    "puto[\"DELTA_roi\"]=pros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=puto.shape[0]\n",
    "pros=[]\n",
    "for i in range(0,n):\n",
    "    if (puto[\"HIGH DELTA\"].iloc[i]==3) :\n",
    "        pros.append(1)\n",
    "   \n",
    "    else:\n",
    "        pros.append(0)\n",
    "puto[\"DELTA_net\"]=pros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=puto.shape[0]\n",
    "pros=[]\n",
    "for i in range(0,n):\n",
    "    if (puto[\"HIGH VOL\"].iloc[i]==2) :\n",
    "        pros.append(1)\n",
    "   \n",
    "    else:\n",
    "        pros.append(0)\n",
    "puto[\"VOL_net\"]=pros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testo=pd.DataFrame(np.random.randint(1,100,size=(1517)))\n",
    "testo[0].quantile([0.7])\n",
    "proba=testo[0]\n",
    "preni=[]\n",
    "for i in proba:\n",
    "    if i<=(69):\n",
    "        preni.append(0)\n",
    "    \n",
    "    else:\n",
    "        preni.append(1)\n",
    "puto[\"TESTtri\"]=preni\n",
    "fp_filter = put_novdet[(puto[\"TESTtri\"] == 1) & (puto[\"TRIGGER\"] == 0)]\n",
    "fp = len(fp_filter)\n",
    "\n",
    "# True positives.\n",
    "tp_filter = put_novdet[(puto[\"TESTtri\"] == 1) & (puto[\"TRIGGER\"] == 1)]\n",
    "tp = len(tp_filter)\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = put_novdet[(puto[\"TESTtri\"] == 0) & (puto[\"TRIGGER\"] == 1)]\n",
    "fn= len(fn_filter)\n",
    "# True negatives\n",
    "tn_filter = put_novdet[(puto[\"TESTtri\"]== 0) & (puto[\"TRIGGER\"] ==0)]\n",
    "tn= len(tn_filter)\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "ppv=tp/ (tp + fp)\n",
    "npv= tn/ (tn + fn)\n",
    "specificity= tn /(fp + tn)\n",
    "accuracy=(tp + tn) / puto.shape[0]\n",
    "print(sensitivity)\n",
    "print(fpr)\n",
    "print( specificity)\n",
    "print(accuracy)\n",
    "print( ppv)\n",
    "print( npv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "putes=puto[puto[\"PRENET\"]==1]\n",
    "putes[\"ROI\"].mean()\n",
    "putes[\"NET\"].mean()\n",
    "putes=puto[puto[\"PREROI\"]==1]\n",
    "puto[\"ROI\"].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
